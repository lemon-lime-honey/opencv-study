# 머신러닝

- Machine Learning
- 인공지능에 포함되는 영역 중 하나
- 데이터 기반으로 컴퓨터를 프로그래밍하는 연구 분야
- 인공지능
  - 주어진 시스템에서 입력을 조절해 출력을 원하는 대로 조절하는 제어기부터
  - 측정 가능한 경험적(heuristic) 속성을 학습해 스스로 판단하는 기능까지의 전반
  - 인간과 비슷한 행동이나 합리적 행동을 통해 특정 문제를 해결하는 데 중점을 둠
- 강인공지능(Strong Artificial Intelligence)
  - 스스로 학습과 인식 등이 가능
  - 지능 또는 지성의 수준이 인간과 근사한 수준까지 이른 경우
  - 인간이 할 수 있는 모든 지적 작업을 수행하도록 설계됨
- 약인공지능(Weak Artificial Intelligence)
  - 인간이 해결할 수 있으나 기존의 컴퓨터로 처리하기 힘든 작업을 처리하기 위한 일련의 알고리즘
  - 현재 많은 곳에서 활용되는 AI 서비스가 이에 해당
- 머신러닝
  - 데이터를 기반으로 학습해 문제를 해결하고 시스템의 성능을 개선하는 데 중점을 둠
  - 데이터를 분석해 일정한 규칙이나 패턴을 찾아 예측 알고리즘(:arrow_right: **모델(Model)**) 생성
  - 모델에 새로운 데이터가 입력됐을 때 모델의 예측값으로 결과 추론
  - 데이터에서 규칙이나 패턴을 찾아내고 정보로 전환해 어려운 문제를 해결하는 데 활용
- 데이터를 기반으로 알고리즘을 구성하므로 통계적 접근법을 사용한다고 볼 수 있음
  - 데이터를 유의미한 정보로 가공해 전달
  - 사전에 수집된 데이터를 통해 기계가 학습한 후 가장 유사한 데이터 등을 분석해 사용자에게 전달
- 딥러닝(Deep Learning)과 신경망(Neural Networks): 머신러닝에 포함됨
  - 딥러닝은 머신러닝의 하위 집합, 신경망은 딥러닝의 하위 집합
  - 신경망
    - Artificial Neural Network: ANN
    - 뉴런의 네트워크에서 영감을 얻은 통계학적 학습 알고리즘
    - 인공 신경망은 신경 세포가 신호를 전달하는 구조와 유사한 방식으로 구현한 알고리즘
      - 생물학적 신경 세포는 단순하게 다른 신경 세포에게 신호를 받아 또 다른 신경 세포에게 전달함
      - 수십억 개 이상의 신경 세포가 네트워크를 이루어 신호의 흐름으로 복잡하고 다양한 활동을 할 수 있음
  - 딥러닝
    - 여러 신경망 계층과 대량의 데이터를 활용해 학습 진행
    - 사용되는 계층: 입력층, 은닉층, 출력층
    - 여러 개의 복잡한 은닉층을 활용해 구현되므로 **딥**
    - 입력층에서 학습하고자 하는 데이터를 전달받고, 여러 개의 은닉층을 지나 출력층에서 결과 반환
    - 인공 신경망에 학습 알고리즘과 데이터를 지속해 제공하여 학습 능력과 사고 능력을 지속적으로 개선함
- 머신러닝은 학습에 사용되는 알고리즘 기법으로 그 유형을 나눌 수 있음
  - 시스템 목적, 현재 상황, 데이터의 특징과 특성, 결과물 등에 따라 나뉨
  - 지도 학습, 비지도 학습, 준지도 학습, 강화 학습 중 하나 이상의 방법을 적용함
  - OpenCV에서는 지도 학습과 비지도 학습을 수행할 수 있음

### 1. 지도 학습

- Supervised Learning
- **훈련 데이터(Training Data)** 와 **레이블(Label)** 의 관계를 알고리즘으로 학습시키는 방법
- 훈련 데이터: 입력 데이터와 출력 데이터로 구성됨
  - 입력 데이터: 알고리즘이 풀고자 하는 문제
    - 벡터 형태로 구성됨
    - 해당 벡터들이 어떤 의미를 내포하고 있는지 labeling 되어 있음
  - 출력 데이터: 문제에 대한 정답
- 레이블링된 데이터를 스칼라 형태로 변환해 벡터와 스칼라 간의 관계를 분석하고 새로운 문제가 입력되었을 때 정답을 유추하는 함수를 찾음
- 훈련 데이터에 정답이 포함되어 있기 때문에 높은 정확도와 안정적인 학습을 기대할 수 있음
  - 모든 훈련 데이터에 레이블이 포함되어야 함
  - 레이블링이 오염되었을 경우 높은 정확도를 기대하기 어려움

#### 회귀 분석

- Regression
- 둘 이상의 변수 간의 관계를 파악하여 독립 변수인 X로부터 연속형 종속 변수인 Y에 대한 모형의 적합도를 측정하는 통계적 분석법
- 간단한 직선 관계부터 복잡한 곡선 형태의 관계까지 다양한 상황에서 적용 가능
  - 선형 회귀, 비성형 회귀
- 데이터를 가장 잘 설명하거나 예측하는 데 도움을 주는 최적의 관계를 찾아 미래 값 예측, 추정 가능

#### 분류

- Classification
- 훈련 데이터에서 지정된 레이블과의 관계를 분석해 새로운 데이터의 레이블을 스스로 판별하는 방법
- 새로운 데이터를 대상으로 할당되어야 하는 카테고리(Category) 또는 범주(Class)를 스스로 판단함
- 이진 분류
  - Binary Classification
  - 새로운 데이터를 대상으로 참인지 거짓인지 분류
- 다중 분류
  - Multiclass Classification
  - 새로운 데이터를 세 개 이상의 카테고리로 나눠 분류

### 2. 비지도 학습

- Unsupervised Learning
- 훈련 데이터에 레이블을 포함시키지 않고 알고리즘이 스스로 독립 변수 간의 관계를 학습하는 방법
- 레이블이 존재하지 않기 때문에 특정한 규칙을 지정해 패턴이나 상관관계를 찾는 모델을 생성함
- 일련의 규칙인 $`f\left(x\right)`$를 통해 $`x`$에 대한 숨겨진 패턴이나 상관관계를 찾는 것을 목표로 함
- 레이블(정답 데이터) 없이 입력 데이터를 대상으로 수행하므로 목표값이 존재하지 않아 사전 학습을 필요로 하지 않음
- 데이터의 근본적인 구조를 발견하거나 직관적으로 처리하기 어려운 작업을 수행할 수 있음
- 레이블이 존재하지 않기 때문에 결과에 대한 성능평가가 어려움

#### 군집화

- Clustering
- 입력 데이터를 기준으로 비슷한 데이터끼리 몇 개의 군집으로 나누는 알고리즘
- 입력 데이터의 특징을 고려해 데이터 분류
  - 같은 군집으로 분류된 데이터끼리는 서로 비슷한 성질(위치, 평균, 편차 등)을 가짐
  - 서로 다른 그룹으로 분류된 데이터는 서로 다른 성질을 가짐

#### 이상치 탐지

- Outlier Detection, Anomaly Detection
- 밀도가 높은 데이터 분포에서 멀리 떨어져 있는 샘플을 찾는 것
- 훈련 데이터나 입력 데이터에 비정상적인 값을 갖는 데이터가 있다면 이를 이상 데이터라 부름
- 정제되지 않은 빅데이터는 정상적이지 않은 데이터가 포함되어 있을 확률이 매우 높음 :arrow_right: 이상 데이터로 간주
- 이상 데이터가 많이 분포하면 학습 모델이나 알고리즘의 정확도와 신뢰도가 낮아짐
- 이상치 탐지는 결함이 있는 데이터나 제품을 찾거나 시계열 데이터(Time Series Data)에서 일반적인 패턴에서 벗어난 패턴 등을 찾음
- 크게 이상치와 이상 탐지로 나뉨
  - 이상치 탐지
    - Outlier 탐지
    - 횡단면 데이터(동일한 시간, 동일 기간에 여러 변수에 대해 수집된 데이터)에서 비정상적인 데이터를 찾는 것
  - 이상 탐지
    - Anomaly 탐지
    - 시계열 데이터에서 비정상적인 데이터를 찾는 것
- 밀도가 높은 지역의 데이터는 정상치(Inlier)로 부르며 밀도가 낮은 지역의 데이터는 이상치로 부름

## 01 K-평균 군집화 알고리즘

- K-Means Clustering Algorithm
- 레이블이 달려 있기 않은 입력 데이터에 레이블을 달아줌
- 방식
    1. 임의의 K개의 중심점(Centroid)을 기준으로 최소 거리에 기반한 군집화 진행
    2. 각각의 데이터는 가장 가까운 중심에 군집을 이룸
    3. 같은 중신에 할당된 데이터는 하나의 군집군으로 형성됨
- 작동 순서
    1. 입력 데이터 위에 K개의 무작위의 중심점을 할당함
    2. 중심점을 기준으로 가장 거리가 가까운 데이터를 동일한 군집군으로 간주
    3. 일부 데이터가 특정 군집군으로 할당되었다면 군집이 할당된 데이터를 기준으로 새로운 중심점 계산
    4. 새로운 중심점을 기준으로 가장 거리가 가까운 데이터를 동일한 군집군으로 간주하고 중심점을 계산하는 연산 반복
- 지속적으로 갱신되는 K개의 중심점을 기준으로 가장 가까운 거리의 데이터를 동일한 군집으로 묶어주는 역할
- 초기에 무작위 중심점과 군집 개수에 의존하므로 군집의 크기, 밀도, 형태 등이 특이하거나 다르면 좋지 않은 결과가 나타날 수 있음
- 알고리즘을 반복하는 횟수에 따라 결과가 다를 수 있음
- 일반적인 정의가 없어 군집화 알고리즘마다 서로 다른 군집을 형성할 수 있음
- **색상 양자화(Color Quantization)** 과정으로도 해석할 수 있음
  - 이미지의 색상 수가 줄어들어 이미지 정보가 압축되는 효과
- 수식 7.1 이미지 압축률  
  $`\underset{i}{\sum}\lVert data_{i} - centers_{labels} \rVert^{2}`$
  - $`i`$: 입력 데이터의 순서
  - $`data`$: 입력 데이터
  - $`centers`$: 중심값
  - $`labels`$: 레이블
- K-평균 군집화 알고리즘 함수
  - C#

    ```csharp
    double retval = Cv2.Kmeans(
        Mat data,
        int k,
        Mat bestLabels,
        TermCriteria criteria,
        int attempts,
        KMeansFlags flags,
        Mat centers
    );
    ```

  - Python

    ```python
    retval, bestLabels, centers = cv2.kmeans(
        data,
        k,
        bestLabels=None,
        criteria,
        attempts,
        flags,
        centers=None
    )
    ```

  - K개의 군집을 설정하고 **입력 데이터(`data`)** 에서 **레이블(`bestLabels`)** 과 **중심점(`centers`)** 을 찾음
    - 입력 데이터
      - float32 형식과 열(column)의 형태로 픽셀 값이 순차적으로 할당되어 있어야 함
      - 세로로 길어지는 형태
    - 레이블
      - 입력 데이터의 크기와 동일한 배열로 생성됨
      - K개의 색인값 정보를 갖게 됨
        - 색인: 중심점 값과 매핑됨
    - 중심점
      - 알고리즘이 찾아낸 군집군의 중심 B, G, R 값을 갖고 있음
      - `int` 형식이 아닌 `float` 형식
  - **기준(`criteria`)**: 군집화의 반복 작업의 조건 설정
  - **시도(`attempts`)**: 초기에 다른 레이블을 사용해 반복 실행할 회수 설정
  - **플래그(`flags`)**: 초기 중심값 위치에 대한 설정
  - **결과값(`retval`)**: 이미지의 압축률

https://github.com/lemon-lime-honey/opencv-study/blob/af06bc5f9332171def30e5602649855703083a8c/07/ex7-1/Program.cs#L1-L46

https://github.com/lemon-lime-honey/opencv-study/blob/af06bc5f9332171def30e5602649855703083a8c/07/ex7-2/Program.py#L1-L18

## 02 K-최근접 이웃 알고리즘

- K-Nearest Neighbor Algorithm: KNN
- 지도 학습에서 사용되는 가장 간단한 분류 알고리즘 중 하나
- 회귀 분석이나 분류에서 사용됨
- 특정 데이터 포인트 주변의 가장 가까운 K개의 이웃 데이터를 기반으로 해당 데이터 포인트를 예측하거나 분류하는 방법
  - 새로운 데이터 주변에 분포한 이웃 데이터의 성질을 토대로 판단
- 간단하고 직관적인 알고리즘으로 구현이 간단하며 이해하기 쉬움
- 데이터 간의 유사성을 기반으로 예측을 수행하기 때문에 복잡한 수학적 모델을 필요로 하지 않음
- 데이터 분포에 대한 가정을 하지 않는 비모수적(Non-parametric) 방법
- 새로운 데이터가 들어올 때마다 모델을 다시 훈련할 필요 없이 바로 적용 가능
  - 실시간 예측에 유용
  - 분류 및 회귀 문제에 모두 적용 가능
  - 분류: 이웃들의 다수결 또는 가중치 평균을 이용해 클래스 결정
  - 회귀: 이웃들의 평균값을 예측값으로 사용
- 모든 데이터 포인트 간의 거리를 계산해야 하므로 데이터가 매우 크거나 차원이 높은 경우 계산 비용이 크게 증가할 수 있음
- 클래스별 데이터의 분포가 불균형하면 이웃들 중에서 특정 클래스가 과도하게 많을 수 있어 예측에 영향을 미칠 수 있음
- 그룹들을 **클래스** 라고 부름
  - **N차원 특징 공간(Feature Space)** 에 표현될 수 있음
  - 이 특징 공간에 새로운 데이터가 주어졌을 때 KNN은 어느 클래스에 분류될지 판단함
- 새로운 데이터가 입력됐을 때 가장 가까운 K개를 비교해 가장 거리가 가까운 개수가 많은 클래스로 분류함
- K가 짝수라면 근접 클래스의 개수가 동점이 발생할 수 있음
  - 동점이라도 거리가 더 가까운 클래스에 가중치를 부여하지 않음
  - K를 홀수로 사용하는 것이 좋음
- 특별한 훈련 방식이 존재하지 않음 :arrow_right: 훈련 데이터 전체를 메모리에 저장하는 것이 훈련의 전부
- 클래스를 분류할 때 메모리에 저장된 모델을 그대로 사용하므로 **인스턴스 기반의 학습** 또는 **게으른 학습** 으로 부름
- 인스턴스 기반 학습의 단점
  - 새로운 데이터를 분류하는 비용이 상대적으로 높음
  - 모든 데이터를 비교해 분류될 클래스를 결정하므로 모든 데이터에 대해 거리를 모두 계산해야 함
  - 데이터에 포함된 속성이나 특징을 모두 계산하게 되므로  
    :arrow_right: **차원 축소** 등을 통해 데이터를 변경하지 않으면 속도가 느리고, 정확도와 신뢰도 보장 불가
- 단순히 데이터를 메모리에 저장하기 때문에 모델을 생성하는 데 들어가는 시간이 상대적으로 짧음
- 모든 데이터를 비교해 분류하므로 비교적 노이즈에 강함

### 1. Fashion-MNIST

- 기존의 MNIST 데이터 세트를 대신해 사용할 수 있게 제공되는 패션 데이터 세트
  - 기존 MNIST 데이터 세트
    - 손으로 쓴 숫자들로 이루어진 데이터 세트
    - 60,000개의 훈련 데이터와 10,000개의 테스트 데이터 제공
  - Fashion-MNIST
    - 10개의 클래스 레이블과 28×28(=784) 크기의 회색조 이미지 제공
    - 훈련 데이터 60,000개와 테스트 데이터 10,000개로 구성됨
- Fashion-MNIST 데이터 세트

  | 파일명 | 내용 | 개수 | 오프셋 바이트 |
  | --- | --- | --- | --- |
  | train-images-idx3-ubyte | 훈련 이미지 | 60,000 | 16 |
  | train-labels-idx1-ubyte | 훈련 레이블 | 60,000 | 8 |
  | t10k-images-idx3-ubyte | 테스트 이미지 | 60,000 | 16 |
  | t10k-images-idx1-ubyte | 테스트 레이블 | 60,000 | 8 |

  - 오프셋 바이트: 1장의 이미지 입력에서 다룬 파일 시그니처의 바이트
    - 이미지는 16바이트 오프셋, 레이블은 8바이트 오프셋
  - 이미지에 포함된 파일 시그니처는 각각 4바이트씩 파일 매직 넘버, 이미지 개수, 이미지 행의 개수, 이미지 열의 개수 포함
  - 레이블에 포함된 파일 시그니처는 파일 매직 넘버, 레이블 개수 포함
  - 이미 이미지의 크기나 파일에 포함된 데이터의 개수를 알고 있으므로 오프셋해 바로 데이터에 접근할 수 있도록 활용
  - 레이블은 0부터 9까지 총 10개의 레이블을 포함함

  | 레이블 | 의미 | 레이블 | 의미 |
  | --- | --- | --- | --- |
  | 0 | T-shirt/top | 5 | Sandal |
  | 1 | Trouser | 6 | Shirt |
  | 2 | Pullover | 7 | Sneaker |
  | 3 | Dress | 8 | Bag |
  | 4 | Coat | 9 | Ankle Boot |

https://github.com/lemon-lime-honey/opencv-study/blob/af06bc5f9332171def30e5602649855703083a8c/07/ex7-3/Program.cs#L1-L46

https://github.com/lemon-lime-honey/opencv-study/blob/af06bc5f9332171def30e5602649855703083a8c/07/ex7-4/Program.py#L1-L25

- Fashion-MNIST를 불러오는 예제

https://github.com/lemon-lime-honey/opencv-study/blob/af06bc5f9332171def30e5602649855703083a8c/07/ex7-5/Program.cs#L1-L56

https://github.com/lemon-lime-honey/opencv-study/blob/af06bc5f9332171def30e5602649855703083a8c/07/ex7-6/Program.py#L1-L29

- Fashion-MNIST 데이터의 이미지를 출력하는 예제

### 2. K-최근접 이웃 알고리즘 적용

- C#에서는 `OpenCvSharp.ML` 네임스페이스를 추가해야 알고리즘 사용 가능
- K-최근접 이웃 알고리즘 클래스
  - C#

    ```csharp
    KNearest knn = KNearest.Create();
    ```

  - Python

    ```python
    knn = cv2.ml.KNearest_create()
    ```

  - 정적 클래스로 생성자를 사용하지 않고 선언
  - 비어있는 모델을 생성하며, 훈련 메서드를 통해 훈련 데이터로 학습을 진행함

- K-최근접 이웃 알고리즘 훈련 메서드
  - C#

    ```csharp
    bool retval = knn.Train(
        Mat samples,
        SampleTypes layout,
        Mat responses
    );
    ```

  - Python

    ```python
    retval = knn.train(
        samples,
        layout,
        responses
    )
    ```

  - **훈련 데이터(`samples`)** 가 어떠한 **배치 구조(`layout`)** 로 구성되어 있는지 확인해 **레이블(`responses`)** 과 매핑함
    - 훈련 데이터: `CV_32F` 형식 사용
    - 레이블: `CV_32F` 형식 또는 `CV_32S` 형식 사용
    - 배치 구조: 두 가지 플래그
      - **행(`ROW_SAMPLE`)**
      - **열(`COL_SAMPLE`)**
    - **결과(`retval`)**
      - `True`: 학습이 정상적으로 진행
      - `False`: 학습에 실패
- K-최근접 이웃 알고리즘 이웃 예측 메서드
  - C#

    ```csharp
    float retval = knn.FindNearest(
        Mat samples,
        int k,
        Mat results,
        Mat neighborResponses = null,
        Mat dist = null
    );
    ```

  - Python

    ```python
    retval, results, neighborResponses, dist = knn.findNearest(
        samples,
        k
    )
    ```

  - **테스트 데이터(`samples`)** 에 대해 **최근접 이웃 개수(`k`)** 에 대한 예측값 반환
  - **반환값(`retval`)**: 첫 번째 테스트 데이터에 대한 예측 결과 반환
  - **결과값(`results`)**
    - 테스트 데이터에 대한 모든 예측 결과 반환
    - `(N, 1)`의 크기를 가지며 `CV_32F` 형식으로 반환
  - **이웃 응답값(`neighborResponses`)** 과 **거리(`dist`)**
    - 예측 결과를 분석하기 위해 사용된 최근접 이웃의 클래스 정보와 거리(L2-Norm) 반환
    - 이웃 응답값과 거리는 `(N, k)` 크기를 가지며 `CV_32F` 형식으로 반환됨

https://github.com/lemon-lime-honey/opencv-study/blob/af06bc5f9332171def30e5602649855703083a8c/07/ex7-7/Program.cs#L1-L67

https://github.com/lemon-lime-honey/opencv-study/blob/af06bc5f9332171def30e5602649855703083a8c/07/ex7-8/Program.py#L1-L36

- K-최근접 이웃 알고리즘 훈련 및 예측 예
- K-최근접 이웃 알고리즘은 데이터를 변경없이 메모리에 그대로 저장하므로 데이터가 동일하고 K 값이 같다면 항상 결과가 같음

https://github.com/lemon-lime-honey/opencv-study/blob/af06bc5f9332171def30e5602649855703083a8c/07/ex7-9/Program.cs#L1-L88

https://github.com/lemon-lime-honey/opencv-study/blob/af06bc5f9332171def30e5602649855703083a8c/07/ex7-10/Program.py#L1-L55

- K-최근접 이웃 알고리즘 예측 시각화 예

### 3. 실제 데이터 평가

- K-최근접 이웃 알고리즘은 **훈련에 사용된** 데이터와 가장 유사한 데이터로 분류됨
- 가령 Sneaker 사진인데 Sneaker가 아닌 Bag나 Sandal로 예측할 수도 있음

(표 7.3)

- 기본 이웃 수 설정 메서드나 KdTree 알고리즘 구현 메서드 등
  - **통계 모델(`StatModel`)** 클래스에서 지원하는 **예측(`Predict`)** 메서드를 통해 예측할 때 사용
- 예측 메서드를 사용하면 K-최근접 이웃 알고리즘의 예측 메서드에서 제공하는 추가적인 정보를 확인할 수 없음

## 03 서포트 벡터 머신

- Support Vector Machine: SVM
- 분류와 회귀 분석에서 사용되는 알고리즘
- 데이터들 간의 기준선을 정의해 새로운 데이터가 어느 경계에 속하는지 판단함
- 결정 경계(Decision Boundary)
  - 한쪽 클래스에 너무 편향적이거나 과대 적합(Overfitting)하지 않은, 가장 효율적으로 경계를 나눌 수 있는 결정 경계를 찾아야 함
  - 효과적으로 경계를 나누지 않으면 경계 근처에서 발생하는 새로운 데이터를 정확히 분류하기 어려움
- 결정 경계는 기존 데이터에서 최대한 멀리 떨어져야 함
  - 기존 데이터에서 멀어질수록 노이즈의 영향을 줄일 수 있어 정확한 분류가 가능해짐
- 최적의 결정 경계는 결정 경계와 가장 가까운 데이터 간의 여백(Margin)이 최대가 되는 위치여야 함
  - 이런 이유로 서포트 벡터 머신을 **최대 여백 분류기(Maximum Margin Classifier)** 라고 부름
  - 최적의 결정 경계에 가장 가까운 데이터에 대한 벡터를 **서포트 벡터(Support Vector)** 라고 부름
- SVM은 최적의 결정 경계를 정의하면 효율적으로 분류할 수 있음
  - 이를 위해 필요한 핵심 데이터는 서포트 벡터이므로 나머지 데이터를 활용하지 않아도 되는 이점이 있음
- 수식 7.2 선형 SVM  
  $`\vec{w}\cdot\vec{x} + b = 0`$
  - 벡터 $`\vec{w}`$: 최적 결정 경계의 법선
  - $`\vec{x}`$: 특징 공간의 포인트
  - $`b`$: 최적의 결정 경계의 오프셋
  - 최적의 결정 경계와 서포트 벡터 사이의 거리가 어느 방향에서도 $`\frac{1}{\lVert \vec{w} \rVert}`$가 되도록 $`\vec{w}`$가 정규화됨

### 1. SVM 커널

- 특징이 세 개 이상으로 늘어나거나 선형적으로 분류할 수 없는 경우 특정 차원의 데이터를 더 높은 차원으로 매핑함
- 더 높은 차원으로 매핑하면 최적의 결정 경계를 찾을 수 있으나, 3차원 이상의 공간에서 결정 경계는 선분이 아니라 평면의 형태가 됨  
  :arrow_right: 초평면(Hyperplane)으로 부름
- 서포트 벡터 머신은 초평면에서 가장 근접한 데이터 간의 여백을 크게 만드는 평면을 찾음
- 2차원 공간의 데이터가 선형으로 분리될 수 없을 때 커널(kernel)을 사용함
  - 데이터를 고차원의 특징 공간으로 매핑하고 다시 본래의 상태로 되돌릴 수 있도록 매핑하는 역할
  - 예를 들어 $`(x_{1}, x_{2})`$의 2차원 공간을 $`(z_{1}, z_{2}, z_{3})`$의 3차원 공간으로 매핑하는 것
- 커널은 $`K\left( \vec{x}, \vec{y} \right)`$로 표현됨
- 매핑은 $`\phi^{T}\left( \vec{x} \right)`$, $`\phi\left( \vec{y} \right)`$로 표현됨
- 이러한 매핑 방식을 **커널 함수(Kernel Function)** 라고 함
- 수식 7.3 커널 함수  
  $`K\left( \vec{x}, \vec{y} \right)`$
  - 커널 함수는 **내적** 연산으로 표현될 수 있음
- 고차원으로 변환해 초평면을 찾는 연산을 진행하면 너무 많은 연산량과 시간이 소모됨 :arrow_right: **커널 트릭** 활용
  - 고차원 데이터의 내적 연산이 아닌 입력된 특징 공간의 벡터만 활용해 동일한 결과를 얻을 수 있음
- 수식 7.4 다항식 커널: 2차원 공간의 점 $`p`$와 $`q`$에 대한 3차원 매핑 예시  
  $`\phi : R^{2} \rightarrow R^{3}`$  
  $`p = \left( p_{1}, p_{2} \right) \qquad q = \left( q_{1}, q_{2} \right)`$  
  $`\phi\left( p \right) = \left( p_{1}^{2}, p_{2}^{2}, \sqrt{2}p_{1}p_{2} \right)`$  
  $`\phi\left( q \right) = \left( q_{1}^{2}, q_{2}^{2}, \sqrt{2}q_{1}q_{2} \right)`$

  $`K\left( p, q \right) = \phi\left( p \right) \cdot \phi\left( q \right)`$  
  $`\qquad \quad \; = \phi\left( p \right)^{T}\phi\left( q \right)`$  
  $`\qquad \quad \; = \left( p_{1}^{2}, p_{2}^{2}, \sqrt{2}p_{1}p_{2} \right) \cdot \left( q_{1}^{2}, q_{2}^{2}, \sqrt{2}q_{1}q_{2} \right)`$  
  $`\qquad \quad \; = p_{1}^{2}q_{1}^{2} + p_{2}^{2}q_{2}^{2} + 2p_{1}q_{1}p_{2}q_{2}`$  
  $`\qquad \quad \; = \left( p_{1}q_{1} + p_{2}q_{2} \right)^{2}`$  
  $`\qquad \quad \; = \left( p \cdot q \right)^{2}`$
  - SVM은 초평면을 계산하는 과정에서 매핑 함수($`\phi`$)를 계산할 필요가 없음
  - 커널 함수는 $`\left( p \cdot q \right)^{2}`$로 동일한 결과값을 얻을 수 있음  
    :arrow_right: 고차원의 데이터로 변환할 필요 없이 본래의 데이터를 계산하는 것으로 동일한 결과를 얻을 수 있음  
    :arrow_right: 커널 트릭
- 커널 함수는 초평면을 생성하는 방법이나 데이터 예측 등에 영향을 미침

(표 7.4)

### 2. SVM 유형

- OpenCV에서는 분류, 분포 추정, 회귀를 위한 다양한 SVM을 지원함
  - 분류를 위한 SVM: C-SVM, $`\nu`$-SVM
  - 분포 추정을 위한 SVM: 단일 클래스 SVM
  - 회귀를 위한 SVM: $`\varepsilon`$-SVR, $`\nu`$-SVR
- C-SVM: C-Support Vector Classification
  - 결정 경계 주변의 여백에 대한 페널티를 조절하는 하이퍼파라미터인 C 값을 사용함
  - C 값이 커질수록 결정 경계의 형태가 굴곡지게 되고, 이 값이 작아질 수록 결정 경계의 형태는 직선에 가까워짐
- $`\nu`$-SVM: Nu-Support Vector Classification
  - $`\nu`$ 값을 사용해 훈련 오류 비율의 상한과 서포트 벡터의 수(비율)의 하한을 제어함
  - $`\nu`$는 0.0에서 1.0 사이의 값으로 설정
- 단일 클래스 SVM: One-Class SVM
  - C와 $`\nu`$를 둘 다 사용
  - 모든 훈련 데이터는 단일 클래스로 간주됨
  - 결정 경계는 다른 모든 클래스로부터 특징 공간을 구분하는 경계를 검출함
- $`\varepsilon`$-SVR: Epsilon-Support Vector Regression
  - SVM의 목적을 반대로 적용
  - 여백을 최대한 크게 하여 데이터가 최대한 안쪽으로 입력될 수 있게 함
  - $`\varepsilon`$의 범위로 초평면 주위의 공간을 정의함
  - $`\varepsilon`$의 거리를 벗어나면 거리에 따라 비용이 증가해 초평면 주변에 있는 지점을 모두 포함시킴
- $`\nu`$-SVR: Nu-Support Vector Regression
  - $`\nu`$-SVM의 처리 방식과 비슷하게 $`\nu`$를 사용해 서포트 벡터가 될 수 있는 수(비율) 설정

(표 7.5)

### 3. 서포트 벡터 머신 적용

- 서포트 벡터 머신 알고리즘 클래스
  - C#

    ```csharp
    SVM svm = SVM.Create();
    ```

  - Python

    ```python
    svm = cv2.ml.SVM_create()
    ```

  - K-최근접 이웃 알고리즘과 동일한 형태
  - 클래스는 정적 클래스로 생성자를 사용하지 않고 선언
  - 비어있는 모델을 생성하며, 훈련 메서드를 통해 훈련 데이터로 학습 진행
- 서포트 벡터 머신 알고리즘 훈련 메서드
  - C#

    ```csharp
    bool retval = svm.Train(
        Mat samples,
        SampleTypes layout,
        Mat responses
    );
    ```

  - Python

    ```python
    retval = svm.train(
        samples,
        layout,
        responses
    )
    ```

  - **훈련 데이터(`samples`)** 가 어떠한 **배치 구조(`layout`)** 로 구성되어 있는지 확인해 **레이블(`responses`)** 와 매핑함
    - 훈련 데이터: `CV_32F` 형식
    - 레이블: `CV_32S` 형식
  - **결과(`retval`)**
    - `True`: 학습이 정상적으로 진행됨
    - `False`: 학습에 실패함
  - 학습을 진행하기 전 커널 함수나 SVM 유형에서 나온 매개 변수를 설정해야 함

  (표 7.6)

- 서포트 벡터 머신 예측 메서드
  - C#

    ```csharp
    float retval = svm.Predict(
        Mat samples,
        Mat results = null
    );
    ```

  - Python

    ```python
    retval, results = svm.predict(
        samples
    )
    ```

  - **테스트 데이터(`samples`)** 에 대한 모든 **결과값(`results`)** 반환
    - 크기: `(N, 1)`
    - 반환 형식: `float32`
  - **반환값(`retval`)**
    - 첫 번째 테스트 데이터에 대한 예측 결과
    - `float` 형식

https://github.com/lemon-lime-honey/opencv-study/blob/af06bc5f9332171def30e5602649855703083a8c/07/ex7-11/Program.cs#L1-L81

https://github.com/lemon-lime-honey/opencv-study/blob/af06bc5f9332171def30e5602649855703083a8c/07/ex7-12/Program.py#L1-L52

- 서포트 벡터 머신 훈련 및 예측 결과 예
- K-최근접 이웃 알고리즘과 비교했을 때 정확도가 더 낮음
    1. 서포트 벡터 머신 알고리즘에서 사용되는 매개 변수의 최적화된 값을 사용하지 않은 경우
        - 최적의 값을 찾기 어렵고 많은 시간이 소요됨
        - Python OpenCV에서는 `svm.trainAuto`를 사용하면 최적의 매개 변수를 찾을 수 있음
          - `svm.train` 메서드에 비해 학습에 오랜 시간이 걸림
          - C# OpenCvSharp에서는 현재 지원되지 않는 메서드
    2. 서포트 벡터 머신 알고리즘에 적합한 훈련 데이터를 사용하지 않은 경우
        - 훈련 데이터들이 초평면으로 분리되는 경계를 찾아야 하는데 데이터가 분리되기 어려운 형태로 구성되어 있는 경우
          - 학습하기 좋은 데이터의 형태가 아니므로 학습 시간이 오래 걸림
          - 낮은 정확도의 모델을 얻어 좋은 결과를 얻지 못함

### 4. 방향 그레이디언트 히스토그램

- 이미지에서 기울기의 크기와 방향으로 지역 히스토그램을 생성해 이미지의 특징으로 사용하는 방법
- 절차
    1. HOG 연산을 진행하기 위해 이미지 크기 변경
        - HOG 알고리즘은 일정한 종횡비를 사용해야 하기 때문에 비율이 일정한 이미지 크기로 변경
    2. **감마 보정(Gamma Correction)** 등을 적용해 픽셀 강도 조정
        - 감마 보정: 영상이나 이미지에 비선형 연산을 진행하여 명암을 보정하는 알고리즘
    3. 이미지에서 기울기의 크기와 방향 계산
        - 소벨 미분 연산과 동일한 방법
        - 소벨 미분을 통해 나온 기울기의 크기와 방향을 **셀(Cell)** 단위로 히스토그램 계산
          - 셀: N×N크기의 픽셀 영역의 묶음
        - 셀 단위로 계산된 기울기의 방향: 0 - 180(부호 없음) / 0 - 360(부호 있음)
          - 일반적으로 부호가 없는 0 - 180의 방향 값 사용
    4. 기울기의 방향과 크기로 히스토그램 구성
        - 히스토그램의 빈도 수 설정
        - 방향과 크기에 대한 히스토그램 계산
        - 방향: 히스토그램의 X축
        - 크기: 히스토그램의 Y축
        - 히스토그램 값은 가중치를 두고 할당됨
        - 히스토그램의 간격은 20
        - 방향 값이 180인 경우 0으로 간주해 게산
    5. 셀을 다시 한 번 더 큰 단위인 **블록(Block)** 으로 묶어 정규화 진행
        - 블록이 이동할 **블록 보폭(Block Stride)** 을 설정하고 합성곱 연산 진행
        - 현재 블록의 각 셀에 대해 기울기 히스토그램을 연결해 $`L_{1}`$-Norm 또는 $`L_{2}`$-Norm 등의 수식을 적용해 특정 벡터로 정규화
          - 현재 OpenCV에서는 $`L_{2}`$-Norm만 적용 가능
- 수식 7.5 HOG 알고리즘의 벡터 크기 계산  
  $`blockCount = \left( \dfrac{winSize.width - blockSize.width}{blockStride.width} + 1 \right) \times \left( \dfrac{winSize.height - blockSize.height}{blockStride.height} + 1 \right)`$  
  $`histogramCount = \left( \dfrac{blockSize.width}{cellSize.width} \right) \times \left( \dfrac{blockSize.height}{cellSize.height} \right) \times bins`$  
  $`VectorCount = blockCount \times histogramCount`$
- HOG 알고리즘 기술자 클래스
  - C#

    ```csharp
    HOGDescriptor hog = HOGDescriptor(
        Size? winSize = null,
        Size? blockSize = null,
        Size? blockStride = null,
        Size? cellSize = null,
        int nbins = 9,
        int derivAperture = 1,
        double winSigma = -1,
        HistogramNormType histogramNormType = HistogramNormType.L2Hys,
        double l2HysThreshold = 0.2,
        bool gammaCorrection = true,
        int nlevels = 64
    );
    ```

  - Python

    ```python
    hog = cv2.HOGDescriptor(
        winSize,
        blockSize,
        blockStride,
        cellSize,
        nbins,
        derivAperture,
        winSigma,
        histogramNormType,
        l2HysThreshold,
        gammaCorrection,
        nlevels,
        signedGradient
    )
    ```

  - 연산을 진행할 이미지의 크기를 **윈도 크기(`winSize`)** 에 할당
  - 적절한 값의 벡터를 구하기 위해 입력
    - **블록 크기(`blockSize`)**
    - **블록 간격(`blockStride`)**
    - **셀 크기(`cellSize`)**
    - **히스토그램 빈도 수(`hbins`)**
  - **미분값(`derivAperture`)**: 기울기 계산에 사용될 미분의 차수
  - **히스토그램 정규화 방법(`histogramNormType`)** 과 **히스테리시스 정규화 임계값(`l2HysThreshold`)** 을 적용해 히스토그램 정규화
  - **감마 보정(`gammaCorrection`)**: 감마 보정 유무
  - **윈도 크기 최대 증가 회수(`nlevels`)**
  - **부호 사용 여부(`signedGradient`)**: Python OpenCV에서만 적용 가능
  - 이 클래스는 윈도 크기, 블록 크기, 블록 간격, 셀 크기 설정에 대한 조건이 존재함  
    $`\left( winSize.width - blockSize.width \right) \% blockStride.width == 0`$  
    $`\left( winSize.height - blockSize.height \right) \% blockStride.height == 0`$  
    $`blockSize.width \% cellSize.width == 0`$  
    $`blockSize.height \% cellSize.height == 0`$

https://github.com/lemon-lime-honey/opencv-study/blob/af06bc5f9332171def30e5602649855703083a8c/07/ex7-13/Program.cs#L1-L101

- HOG 알고리즘은 매개 변수가 달라질 때마다 출력되는 벡터의 크기가 다름  
  :arrow_right: `descriptor` 변수의 길이와 이미지의 개수로 나누어 간단하게 처리

https://github.com/lemon-lime-honey/opencv-study/blob/af06bc5f9332171def30e5602649855703083a8c/07/ex7-14/Program.py#L1-L58

## 04 심층 신경망

- Deep Neural Network: DNN
- 심층 신경망 모듈은 OpenCV 3.1 이후부터 사용 가능
- OpenCV 3.3에서 opencv_contrib 저장소에서 주 저장소로 승격됨
- 성능 향상을 위해 SSE, AVX, AVX2 및 NEON과 같은 병렬 프로세스 기술 활용
- 고속 연산을 위해 CUDA 지원
- 머신러닝 및 딥러닝 프레임워크 설치 없이 미리 학습된 딥러닝 모델 파일을 심층 신경망 모듈로 실행 가능
- OpenCV는 딥러닝을 위한 라이브러리가 아니므로 **순전파(Forward)** 와 **추론(Inference)** 만 가능함
- 심층 신경망 모듈에서 지원되는...
  - 딥러닝 프레임워크: Caffe, Tensorflow, Torch, Darknet, ONNX 등
  - 주요 모델: AlexNet, GoogLeNet, ResNet, SSD, YOLO, Faster-RCNN 등
- C# OpenCvSharp에서는 `OpenCvSharp.Dnn`에 포함됨
- Python OpenCV에서는 `cv2.dnn`에 포함됨
- Net 클래스
  - C#

    ```csharp
    Net net = CvDnn.ReadNet(
        string model,
        string config = "",
        string framework = ""
    );
    ```

  - Python

    ```python
    net = cv2.dnn.readNet(
        model,
        config=None,
        framework=None
    )
    ```

    - `Net` 클래스의 `ReadNet` 메서드는 딥러닝 네트워크를 읽는 역할을 함
      - 학습된 모델의 원본 프레임워크를 자동으로 감지
    - **모델(`model`)**: 학습된 모델의 가중치를 저장하고 있는 이진 파일의 경로
    - **설정(`config`)**: 네트워크 구성에 관한 텍스트 파일의 경로
    - **프레임워크(`framework`)**: 형식을 결정하기 위한 딥러닝 프레임워크의 태그
- 모델 파일
  - 딥러닝 프레임워크를 통해 나온 모델의 변수 및 그래프에 대한 정보를 담고 있는 이진 파일
  - 사람이 눈으로 읽고 정보를 해석하기에는 어려움
- 설정 파일
  - 텍스트 형태로 구성됨
  - 모델의 구조 파악 가능
  - 구조를 파악하거나 추론할 때 적용할 매개 변수의 설정 등 확인 가능

(표 7.7)

- `readNet` 메서드와 매개 변수 설정을 적용해 현재 지원되는 딥러닝 프레임워크를 불러올 수 있음
  - `CvDnn.ReadNetFromCaffe` 또는 `cv2.dnn.readNetFromCaffe` 메서드처럼 특정 프레임워크를 지정해 모델을 불러올 수도 있음
- 모델을 정상적으로 불러왔다면 이미지를 **블롭(Blob)** 형식으로 변경해야 함
  - 블롭
    - Binary Large Object
    - 이미지나 비디오 프레임과 같은 다양한 유형의 데이터를 나타내는 이진 데이터
  - 딥러닝에서 블롭은 네트워크에 입력으로 전달되기 전에 이미지를 전처리하고 정규화하는 데 사용됨
  - 블롭은 동일한 전처리 방식, 차원, 채널 등으로 구성된 하나 이상의 이미지를 의미함
- 블롭 연산
  - 평균 차감법, 크기 조절, 채널 교체 등을 수행함
    - 이미지에 전처리를 적용해 딥러닝 프레임워크에서 데이터를 쉽게 읽을 수 있는 형태로 바꿔주는 역할
  - OpenCV에서는 4차원 블롭을 생성하며, 이미지 수(N), 채널 수(C), 이미지 높이(H), 이미지 너비(W)의 차원 순서를 갖는 배열 반환
- 단일 블롭 적용 함수
  - C#

    ```csharp
    net retval = CvDnn.BlobFromImage(
        Mat image,
        double scaleFactor = 1.0,
        Size size = default,
        Scalar mean = default,
        bool swapRB = true,
        bool crop = true
    );
    ```

  - Python

    ```python
    retval = cv2.dnn.blobFromImage(
        image,
        scalefactor=None,
        size=None,
        mean=None,
        swapRB=None,
        crop=None,
        ddepth=None
    )
    ```

  - **원본 이미지(`image`)** 에 **스케일 계수(`scaleFactor`)** 를 적용해 픽셀 배율 변경
    - 픽셀 값이 0 - 1 범위로 학습된 모델이라면 1/255로 사용해 정규화 진행
  - **크기(`size`)**: 신경망 모델에서 요구하는 특정 크기로 이미지의 크기를 변경하는 역할
  - **평균 차감(`mean`)**
    - 이미지에서 차감할 픽셀(R, G, B) 값
    - 신경망 모델에서 사용된 훈련 데이터에서 차감된 픽셀
      - 픽셀 차감; 입력 이미지에서 조명 변화의 영향을 줄이는 역할을 할 수 있음
  - **RGB 채널 변경(`swapRB`)**
    - Red 채널과 Blue 채널의 순서를 바꾸는 역할
    - 텐서플로는 RGB 채널 순서를 사용하므로, RGB 형식의 이미지로 학습이 진행됐다면 채널을 변경해 사용함
  - **자르기(`crop`)**
    - 원본 이미지의 크기를 변경한 다음, 이미지 자르기 기능 수행 여부 설정
  - **출력 이미지 정밀도(`ddepth`)**
    - 파이썬 OpenCV에서만 지원
    - 출력 이미지의 정밀도 설정
  - **반환값(`retval`)**
    - NCHW 순서의 4차원 `Mat` 데이터 반환
- 원본 이미지에 대해 블롭을 적용한 `Mat` 데이터가 생성되었다면 이 데이터를 네트워크에 대한 새 입력값으로 설정해야 함
  - 그래야 추론을 시작할 수 있는 상태가 됨
- 네트워크 입력 메서드
  - C#

    ```csharp
    net.SetInput(
        Mat blob,
        string name = ""
    );
    ```

  - Python

    ```python
    net.setInput(
        blob,
        name=None,
        scalefactor=None,
        mean=None
    )
    ```

  - **블롭 데이터(`blob`)**
    - 네트워크 입력 메서드 설정
    - `CV_32F`, `CV_8U` 형식만 적용 가능
  - **이름(`name`)**
    - 입력층의 이름을 설정해 추론을 진행할 수 있게 설정
    - 필수 값이 아니므로 이름을 설정할 필요가 없는 경우 할당하지 않아도 됨
  - **스케일 계수(`scaleFactor`)** 와 **평균 차감(`mean`)**
    - Python OpenCV에서만 지원하는 기능
    - 블롭 적용 함수의 매개 변수의 의미와 동일
    - 추가로 곱과 차감 연산 진행 가능
    - 일반적으로 블롭 적용 함수에서 스케일 계수와 평균 차감을 적용함
- 블롭을 네트워크에 입력했다면 순전파를 적용해 딥러닝 모델을 사용할 수 있음
  - 네트워크의 입력층부터 출력층까지 차례대로 변수들을 계산하고 추론 결과를 반환함
- 순전파 메서드
  - C#

    ```csharp
    mat outputBlobs = net.Forward(
        string? outputName = null
    );
    ```

  - Python

    ```python
    outputBlobs = net.forward(
        outputName=None
    )
    ```

  - **출력 이름(`outputName`)** 에 출력하려는 특정 계층의 이름까지의 연산 결과를 **출력 블롭(`outputBlob`)** 으로 반환
    - 출력 블롭: 지정된 계층의 첫 번째 출력에 대한 블롭이 반환됨
    - 추론에 사용한 딥러닝 프레임워크나 모델에 따라 출력되는 블롭의 구조가 다름
    - 사용한 모델의 네트워크 구조를 이해하고 있지 않다면 사용하는 데 큰 어려움을 겪을 수 있음

(표 7.8)

(표 7.9)

(표 7.10)

### 1. 카페: 이미지 분류(구글넷)

- Caffe
  - 딥러닝 프레임워크 중 하나
  - 주로 이미지 분류 및 객체 감지 등 작업에서 활용
  - 합성곱 신경망(Convolutional Neural Network: CNN)을 구현하고 학습시키는 데 중점을 둠
- GoogLeNet
  - 이미지 분류 작업에서 높은 성능을 보인 딥러닝 모델
  - 총 224개의 계층으로 구성됨
  - 다양한 크기의 필터와 **풀링(Pooling)** 연산을 동시에 사용해 특징 추출
    - 풀링: 커널 영역 내에서 최대값 또는 평균값을 추출해 차원을 줄이거나 중요한 정보를 강조하는 연산

https://github.com/lemon-lime-honey/opencv-study/blob/af06bc5f9332171def30e5602649855703083a8c/07/ex7-15/Program.cs#L1-L32

https://github.com/lemon-lime-honey/opencv-study/blob/af06bc5f9332171def30e5602649855703083a8c/07/ex7-16/Program.py#L1-L18

1. **클래스 레이블 파일(`bvlc_googlenet.txt`)** 은 텍스트 파일이므로 `IO` 모듈을 사용해 값을 불러옴
2. `Net` 클래스를 활용해 카페 프레임워크의 모델을 읽어옴
3. 모델 파일이 정상적으로 불러와졌다면 추론을 진행할 이미지에 블롭 적용
    - 여기서 사용되는 **크기(`size`)** 와 **평균 차감(`mean`)** 매개 변수
      - 구글넷을 훈련할 때 사용된 값이 `(224, 224)`와 `(104, 117, 123)`을 적용함
        - 이 모델은 224×224 크기의 이미지로 학습됨
        - 학습에 사용된 이미지들의 평균 RGB 픽셀 값은 (104, 117, 123)
    - 추론 이미지는 224×224 크기로 변환되며, 평균 RGB 픽셀 값을 감산함
      - RGB 이미지에서 각 채널 별로 평균 값을 빼는 것은 일반적인 전처리 기법
4. 블롭 데이터가 생성되면 네트워크 입력 메서드에 전달해 추론을 진행할 수 있는 상태로 구성
5. 블롭 데이터가 네트워크 입력층에 배치되면 순전파 메서드를 통해 추론 진행
    - 순전파 메서드에 입력된 `prob`은 출력층에 해당하는 계층의 이름을 나타냄
    - 필요한 계층의 이름을 확인하는 방법
      - **설정 파일(`bvlc_googlenet.prototxt`)** 검토
      - 네트워크에서 사용된 계층 이름을 반환하는 메서드 활용
    - `outputblobs`: `float32` 형식의 `(1, 1000)` 크기를 가짐
      - 첫 번째 차원
        - 배치 크기로 입력된 이미지의 개수
        - 단일 블롭 적용 함수를 사용했으므로 첫 번째 차원은 항상 1을 가짐
        - 다중 블롭 적용 함수를 사용하는 경우 입력된 이미지의 개수만큼 차원이 늘어남
      - 두 번째 차원
        - 위치: 각 클래스별 ID
        - 값: 확률
6. 추론 결과 확인
    - 최소/최대 위치 반환 함수를 사용
      - `inputBlob` 데이터의 **최대값(`classProb`)** 과 **최대값 위치(`classID`)** 로 추론된 클래스와 확률 확인 가능
      - 최대값 위치의 X: 클래스 레이블 파일의 순서와 일치
        - 최대값: 추론된 결과값의 확률
      - 최대값 위치의 Y: 단일 블롭 함수를 사용해 항상 `0` 반환
        - 값: 확률을 의미하는 `0.0 - 1.0` 범위의 값을 가짐
    - 이미지에서 가장 높은 추론 확률의 데이터 제공
    - 다른 추론 결과도 확인하려면 `outputBlobs` 변수의 값 분석

### 2. 다크넷: 객체 검출(YOLO)

- Darknet
  - 딥러닝을 활용한 객체 감지를 수행하는 데 사용되는 신경망 프레임워크
  - YOLO(You Only Look Once) 알고리즘이 대표적으로 사용됨
- YOLO
  - 실시간 객체 감지를 위한 모델
  - 매우 빠른 추론 속도와 정확도 제공
  - 이미지를 그리드로 나누어 각 그리드 셀에 대한 객체의 클래스와 해당 객체의 **경계 상자(Bounding Box)** 예측 가능
  - 다양한 모델을 제공하기 때문에 추론 속도와 정확도의 균형을 맞추기가 쉬움

https://github.com/lemon-lime-honey/opencv-study/blob/af06bc5f9332171def30e5602649855703083a8c/07/ex7-17/Program.cs#L1-L86

https://github.com/lemon-lime-honey/opencv-study/blob/af06bc5f9332171def30e5602649855703083a8c/07/ex7-18/Program.py#L1-L56

1. 추론에 활용되는 파일들의 경로를 지정해 파일을 불러옴
    - YOLOv3 모델: 객체의 영역을 탐지 가능, 객체의 클래스 이름, 확률, 영역을 저장할 변수인 `labels`, `scores`, `bboxes` 선언
2. 추론을 수행할 이미지에 블롭 적용
    - **스케일 계수(`scaleFactor`)** 는 `255`로 값을 나누어 사용
    - YOLOv3은 0.0 - 1.0 범위의 픽셀 값으로 학습되었기 때문에 255로 나누어 적용
    - **크기(`size`)** 와 **자르기(`crop`)** 매개 변수
      - YOLOv3를 훈련할 때 사용된 `(412, 412)` 값 적용
      - 이미지를 자르지 않도록 설정
3. 네트워크 입력 메서드에 블롭 데이터를 전달해 추론을 진행할 수 있는 상태로 설정
    - **설정 파일(`yolov3.cfg`)** 에는 출력층에 대한 이름이 작성되어 있지 않음
    - 네트워크에서 사용된 계층 이름을 반환하는 메서드를 활용해 출력층의 이름을 가져옴
    - 출력층이 총 3개(`yolo_82`, `yolo_94`, `yolo_106`)로 구성되어 있으므로
      - C#: 3개의 Mat 데이터를 하나의 `outputBlobs`로 묶을 수 있도록 오버로딩된 메서드 사용
      - Python: 순전파 메서드에서 3개로 구성된 리스트 반환
4. `outputBlobs` 변수를 반복해 검출된 객체에 대한 정보를 가져옴
    - 반환되는 배열은 검출된 객체의 클래스, 영역, 확률 등을 포함함
    - **검출된 객체의 신뢰도(`confidence`)**: 검출된 사각형 크기 내부에 객체가 존재할 확률
    - **객체의 확률(`probability`)**: 사각형 크기 내부에 어떤 객체가 제일 높은 개연성을 갖는가에 대한 확률
    - 검출된 객체의 신뢰도가 90% 이상인 데이터로 연산 진행
    - 최소/최대 위치 반환 함수를 활용해 `prob` 데이터의 **최대값 위치(`classID`)** 로 객체의 레이블을 가져옴
      - 단일 블롭: (그리드 셀의 수, 클래스 정보)
      - 다중 블롭: (배치 크기, 그리드 셀의 수, 클래스 정보)
    - 객체의 확률은 **클래스 번호 + 5** 의 구조를 가짐
      - 클래스 번호는 0부터 79까지의 값이므로 5를 더해 [X 좌표, Y 좌표, 너비, 크기, 검출된 객체의 신뢰도]를 건너뜀
    - 객체의 확률 값을 한 번 더 확인해 90% 이상인 데이터만 저장
    - 반환된 객체의 위치 및 크기 정보는 이미지에 대한 상대 좌표 사용 :arrow_right: 원본 이미지의 너비와 높이를 곱함
    - `labels`, `scores`, `bboxes` 변수에 값이 저장된 경우 이를 기반으로 비최대값 억제 수행
      - 비최대값 억제
        - 하나의 객체가 여러 번 중복으로 검출되는 현상을 최소화하기 위해 국지적인 최대값을 찾아 해당 값을 남기고 나머지 값 삭제
    - 비최대값 억제 함수의 매개 변수: 경계 상자, 확률, 확률 임계값, 비최대 억제 임계값
      - 확률 임계값: 특정 확률 이상의 값만 사용되도록 필터링
      - 비최대 억제 임계값: 경계 상자를 필터링하는 데 사용: 이 값을 너무 크게 사용하면 모든 사각형이 제거될 수 있음
    - 반환되는 `indices` 변수는 해당 조건에 부합하는 색인 값 반환

### 3. 텐서플로: 세그멘테이션(Mask R-CNN)

- TensorFlow
  - 머신러닝 프레임워크
  - 머신러닝 및 딥러닝 모델을 쉽게 구현하고 효율적으로 학습시키기 위한 다양한 도구와 라이브러리 제공
- Mask R-CNN
  - Faster R-CNN의 확장
  - 객체의 경계 상자뿐만 아니라 객체의 픽셀 수준의 분할 정보(마스크) 생성 가능
  - 객체 검출과 분할을 통합해 객체의 윤곽과 내부 구조를 동시에 파악하는 데 적합함

https://github.com/lemon-lime-honey/opencv-study/blob/af06bc5f9332171def30e5602649855703083a8c/07/ex7-19/Program.cs#L1-L65

https://github.com/lemon-lime-honey/opencv-study/blob/af06bc5f9332171def30e5602649855703083a8c/07/ex7-20/Program.py#L1-L43

1. 추론에 활용되는 파일들의 경로를 지정해 파일을 불러옴
2. 추론을 수행할 이미지에 블롭 적용
    - **RGB 채널 변경(`swapRB`)**: `true`
    - **자르기(`crop`)**: `false`
3. 네트워크 입력 메서드에 블롭 데이터를 전달해 추론을 진행할 수 있는 상태로 구성
    - 경계 상자와 세그멘테이션 결과를 활용할 예정이므로 순전파 메서드에 `detection_out_final` 과 `detection_masks` 계층 이름 전달
    - `detection_out_final` 계층
      - 객체의 경계 상자 정보와 해당 객체의 신뢰도 등을 포함하는 계층
      - 객체의 위치 및 클래스 정보를 얻을 수 있음
    - `detection_masks` 계층
      - 객체의 세그멘테이션 마스크 정보를 포함하는 계층
      - 검출된 객체의 정확한 형태 및 경계를 나타내는 마스크 제공
4. `outputBlobs` 변수: 경계 상자와 세그멘테이션 반환
    - **경계 상자(`boxes`)**: `(1, 1, 100, 7)`의 차원으로 반환
      - 첫 번째 차원
        - 배치 크기
        - 단일 블롭 적용 함수를 사용했기 때문에 항상 1
      - 두 번째 차원
        - 차원 형태를 맞추기 위한 차원으로 사용되지 않는 차원
      - 세 번째 차원
        - 경계 상자의 개수
        - 이 모델에서는 가장 우수한 1004ㅐ의 경계 상자가 선택되어 반환됨
      - 네 번째 차원
        - 상세한 추론 결과를 담음
        - 7
          - 이미지 식별 번호(`index`)
          - 검출된 객체의 클래스 ID(`class`)
          - 검출된 객체의 신뢰도(`confidence`)
          - 좌측 상단 X 좌표(`x1`)
          - 좌측 상단 Y 좌표(`y1`)
          - 우측 하단 X 좌표(`x2`)
          - 우측 하단 Y 좌표(`y2`)
    - **세그멘테이션(`masks`)**
      - `(100, 90, 15, 15)` 의 차원으로 반환
      - 첫 번째 차원
        - 경계 상자의 개수
        - 비최대값 억제를 수행한 다음 나타나는 상위 100개의 경계 상자와 매칭됨
      - 두 번째 차원
        - 해당 모델에서 검출할 수 있는 클래스 개수
        - 이 모델은 COCO 데이터세트에서 훈련되었으므로 90개의 클래스 검출 가능
      - 세 번째, 네 번째 차원
        - 마스크 정보로 검출된 객체의 마스크 정보를 15×15 크기로 예측
    - 검출된 객체의 신뢰도가 90% 이상인 데이터로 연산을 진행하게 구성
    - 검출된 객체의 클래스와 좌표를 활용해 이미지 위에 연산 결과 표시
      - 이를 위해 현재 경계 상자와 동일한 색잉ㄴ과 클래스 값을 갖는 마스크를 추출함
      - (해당 경계 상자, 해당 클래스, 마스크 너비, 마스크 높이)
    - 마스크 정보
      - 객체의 분할 영역을 특성 맵의 그리드에 매핑해 얻는 정보
        - 15×15 크기의 마스크로 예측됨
      - 이는 Mask R-CNN 모델의 영역 제안 네트워크와 관심 영역 정렬에 의해 경계 상자 영역을 특성 맵의 그리드에 맞게 매핑하기 때문
        - 영역 제안 네트워크
          - Region Proposal Network: RPN
          - 이미지 내에서 후보 객체의 경계 상자 제안
        - 관심 영역 정렬
          - Region of Interest Align
          - 경계 상자를 특성 맵의 그리드에 정확하게 매핑하여 객체 분할

- OpenCV에서 딥러닝 프레임워크의 추론 방법 및 코드 구성은 대체로 비슷
- 입력층과 출력층을 설정하는 방법이나 추론 결과를 활용하기 위해 데이터 형식을 변경하는 방법은 프레임워크나 모델마다 다름

### 4. ONNX: 얼굴 검출 및 랜드마크(YuNet)

- ONNX
  - Open Neural Network Exchange
  - 딥러닝 모델의 구조와 가중치를 표현하기 위한 중립적인 형식을 제공해 프레임워크 간에 호환성을 가지는 딥러닝 모델의 표준 중 하나
  - 다양한 딥러닝 프레임워크 간에 모델을 변환하고 공유할 수 있는 기능을 제공하는 중간 언어라 할 수 있음
  - 모델의 구조를 그래프 형태로 표현해 딥러닝 프레임워크 간에 모델을 효율적으로 변환하고 실행하는 데 편리한 방법 제공
- YuNet
  - 얼굴 검출과 랜드마크 검출 가능
  - 에지 디바이스(데이터를 생성하는 지점 근처에서 데이터 처리를 수행하는 장치)를 대상으로 설계되어 빠른 처리 속도 제공
  - 앵커 프리(객체 검출에서 객체의 위치를 직접적으로 예측하는 방식) 구조의 검출 모델로 높은 유연성을 가짐
  - 다른 작은 크기의 검출 모델보다 더 적은 매개 변수를 가짐

https://github.com/lemon-lime-honey/opencv-study/blob/af06bc5f9332171def30e5602649855703083a8c/07/ex7-21/Program.cs#L1-L136

https://github.com/lemon-lime-honey/opencv-study/blob/af06bc5f9332171def30e5602649855703083a8c/07/ex7-22/Program.py#L1-L79

- ONNX 표준은 하나의 모델 파일만 필요
  - 모델을 저장하고 공유하는 데에 표준화된 형식을 사용하기 때문
  - 모델 설정 파일 등이 존재하지 않아 모델의 구조를 확인하기 어려울 수 있음
  - 이런 문제를 해결하기 위해 **네트론(Netron)** 과 같은 시각화 도구를 활용해 모델 구조 확인
- YuNet
  - 입력층: 1×1×640×640 크기의 입력이 사용됨
    - 블롭의 크기를 640×640 크기로 설정해야 함
  - 출력층: 총 12개의 계층 반환
    - 숫자 8, 16, 32
      - 간격(stride)
      - YuNet은 얼굴을 검출할 때 이미지를 간격 크기의 그리드로 나누고 해당 그리드 내에서 얼굴을 검출함
      - 각 그리드 별로 하나의 얼굴 검출
      - 간격의 크기에 따라 검출되는 얼굴의 크기와 정확도가 조절됨
      - 그리드 영역 내의 상대 좌표로 얼굴의 위치를 표현함
      - 얼굴 검출의 다양성과 정확도를 조절하는 데 중요한 역할
        - 작은 간격
          -미세한 얼굴 특징을 잡아낼 수 있음
          - 계산 비용이 높아짐
        - 큰 간격
          - 계산 비용 낮아짐
          - 미세한 얼굴 특징을 놓칠 수 있음
        - 다양한 그리드로 얼굴 검출을 수행해 검출의 성능과 효율성을 높임
    - 경계 상자(`bbox`)
      - `bbox_8`: 1×6400×4 크기로 출력 :arrow_right: 배치 크기×채널 수(감지 수)×경계 상자 정보
    - 클래스 확률(`cls`)
      - 주어진 영역에서 특정 객체 클래스에 속할 확률
    - 키 포인트(`kps`)
      - `kps_8`
        - 얼굴에 대한 랜드마크 검출: 총 10개
        - 오른쪽 눈 X 좌표(0), 오른쪽 눈 Y 좌표(1)
        - 왼쪽 눈 X 좌표(2), 왼쪽 눈 Y 좌표(3)
        - 코 끝 X 좌표(4), 코 끝 Y 좌표(5)
        - 입의 오른쪽 X 좌표(6), 입의 오른쪽 Y 좌표(7)
        - 입의 왼쪽 X 좌표(8), 입의 왼쪽 Y 좌표(9)
    - 객체 존재 확률(`obj`)
      - 특정 위치에 객체가 존재할 확률
- `outBlobNames`: 마지막 계층의 문자열을 반환하므로 원하는 계층 출력 순서가 다를 수 있음
    1. 총 12개의 계층이 반환되므로 `bbox`, `cls`, `kps`, `obj`로 묶어 나눔
    2. 간격마다 반복문 수행
    3. 그리드의 열과 행 계산
        - 상대좌표를 절대좌표로 변환하기 위해 행, 열, 그리드 색인 순서를 활용해야 함
    4. 점수 계산
        - 클래스 확률(`clsScore`)과 객체 존재 확률(`objScore`)을 조합해 최종 예측의 신뢰도 계산
    5. 경계 상자와 키 포인트 추출
        - 경계 상자: 중심값 X, 중심값 Y, log(너비), log(높이)로 반환
          - 중심값
            - 현재 행과 열을 더해 그리드 영역 내 위치로 조절, 그리드 간격을 곱해 절대 좌표로 변경
            - 입력 크기로 나누고 원본 이미지 크기를 곱해 원본 이미지와 동일한 스케일로 변경
          - 크기 반환값은 로그가 취해짐
            - 모델이 예측하는 크기의 범위를 축소하기 위함
            - 다시 지수 함수를 사용해 예측 크기를 확장하고 동일하게 그리드 간격을 곱함
            - 크기는 좌표를 의미하지 않으므로 현재 행과 열은 사용하지 않아도 됨
            - 경계 상자의 좌표를 원본 이미지와 동일한 스케일로 변경하기 위해 입력 크기를 나누고 원본 이미지를 곱함
        - 키 포인트: 랜드마크의 좌표
          - 경계 상자 좌표 처리 방법과 동일하게 계산
    6. 비최대값 억제 알고리즘을 수행해 우수한 경계 상자 및 랜드마크만 출력
