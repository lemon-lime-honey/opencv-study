# 컴퓨터비전의 이해

## 01 컴퓨터비전이란?

### 1. 컴퓨터비전이란?

- 컴퓨터와 디지털 시스템을 사용해 시각적인 정보를 처리하고 해석하는 기술 및 분야
- 인공지능의 한 분야로 볼 수 있으며, 기계에 시각적 능력을 부여해 시각 데이터에서 **특징(Feature)** 이나 **특성(Characteristic)** 을 파악하는 데 쓰임

### 2. 영상 처리의 필요성

- **영상 처리(Image Processing)** 는 **컴퓨터 그래픽스(Computer Graphics)** 및 컴퓨터비전과 밀접한 관련이 있음
  - 컴퓨터 그래픽스: 컴퓨터를 사용해 실제 세계의 영상을 조작하거나 새로운 영상을 생성하는 기술
  - 영상 처리
    - 주로 입력된 영상으로부터 정보를 추출하거나 특정 패턴을 인식하는 과정을 포함함
    - 영상의 픽셀 수준의 필터링 및 변환과 같은 작업을 다룸
  - 컴퓨터비전
    - 입력된 영상 내의 객체나 패턴을 인식하고 해석하는 것에 더 중점을 둠
    - 영상 처리 결과를 활용해 객체 감지, 분류, 추적 등 고급 기능을 연구하고 개발

### 3. 영상 처리의 한계점

- 영상 처리
  - 이미지 내에서 불필요한 정보를 제거하고 필요한 정보를 추출하거나 가공된 정보를 생성하는 과정
  - 이를 통해 컴퓨터는 시각적인 입력을 해석하고 판단할 수 있는 능력을 갖추게 됨
  - 이미지나 비디오 데이터의 가공 및 해석에 사용됨
- 컴퓨터의 시각 능력을 인간이 지닌 시각 능력과 동일한 수준까지 이끌어내는 것은 매우 어려운 일
  - 시점, 환경에 따라 같은 물체가 다르게 보일 수 있음
  - 3차원 객체를 2차원 평면에 표현하면 원근 효과나 곡면의 단순화 등으로 정보의 손실, 왜곡, 변형 발생
  - 인간은 모든 감각을 활용하고, 기억과 경험을 고려하기 때문에 객체를 신속하게 구분할 수 있음: 컴퓨터는 아님
  - 인간은 시각적인 정보를 통해 객체, 전경, 배경을 한 번에 인식하며 거리와 깊이를 직관적으로 파악할 수 있음: 컴퓨터는 아님

### 4. 데이터 변형

- 컴퓨터는 이진 데이터로 값을 표현하므로 디지털 이미지도 이진 데이터로 표현됨
- 컴퓨터가 아날로그 정보를 디지털 데이터로 변환하려면 **샘플링(Sampling)** 과 **양자화(Quantization)** 과정이 필요함
- 샘플링
  - 연속적인 아날로그 신호를 일정한 간격으로 끊어 이산적인(Discrete) 샘플로 변환하는 과정
  - 아날로그 신호의 연속성을 잃지만 컴퓨터에서 처리하기 용이한 형태로 변환됨
  - 샘플링된 값은 여전히 시간에 대해 무한한 소수 형태의 값을 가질 수 있는데, 이는 양자화로 해결 가능
- 양자화
  - 연속적인 값을 디지털화하는 과정
  - 샘플링된 값들을 정확한 실수가 아닌 가능한 값들의 집합 중 가장 근접한 값으로 근사화함
  - 무한한 연속 범위를 가지는 데이터를 유한한 디지털 값들로 대표 가능
  - 데이터의 정확성과 저장 공간 사이의 균형을 맞추는 중요한 요소
  - 정밀한 양자화: 높은 데이터 품질을 제공하지만 더 많은 저장 공간을 요구함
  - 낮은 정밀도의 양자화: 작은 데이터 크기를 보장하지만 정보의 왜곡 가능성이 높아짐

### 5. 이미지 데이터

- 아날로그 데이터를 디지털 데이터로 변환하기 위해 샘플링과 양자화를 거치면서 정보 손실 발생
- 이후 이미지를 컴퓨터에서 표시하기 위해 디지털 데이터를 압축하면 또 다른 손실 발생
- RGB 형식 이미지
  - 각 픽셀은 빨간색, 초록색, 파란색 성분으로 구성
  - 이러한 성분들이 이미지 내에 있는 각 픽셀마다 저장됨
  - 이미지 크기와 동일한 개수의 픽셀 데이터 존재: 각 성분은 0부터 255까지의 숫자 범위 내에서 특정한 값을 갖게 됨
- 컴퓨터비전은 픽셀 데이터 간 값의 높고 낮음, 인접성, 배치 형태, 연속성 등을 통해 이미지에서 유의미한 정보를 구분하고 판단
  - 이미지 전체를 바라보는 것이 아니라 행렬 형태로 구성된 숫자 값을 보고 해석하여 다양한 패턴, 구조, 특징 인식

### 6. OpenCV란?

- Open Source Computer Vision Library
- 실시간 영상 처리에 중점을 둔 영상 처리 라이브러리
- 인텔에서 최초 개발. 크로스 플랫폼.
- 계산 효율성과 실시간 처리에 중점을 두고 설계됨

### 7. OpenCV의 역사

- 인텔 연구소에서 시작된 프로젝트 중 하나
- 실시간 광선 추적과 3D 디스플레이 처리 등 다양한 프로젝트를 위해 개발됨
- 1999: 공식적인 개발 시작
- 2006: 1.0 버전 배포
- 2009: 2.x 버전 배포
  - iOS 및 안드로이드를 포함한 새로운 플랫폼에 대한 지원
  - CUDA, OpenCL을 통한 GPU 가속 기능 추가
  - Python, Java 사용자에게 완벽에 가까운 인터페이스 제공
  - 깃허브 저장소를 통한 배포 가능해짐
-2015: 3.x 버전 배포
  - 프로젝트 구조 변경, 프로젝트 기여자들을 통해 최점단 알고리즘 적용
  - 속도 향상

## 02 알고리즘 설계

- 알고리즘
  - 어떤 문제를 해결하기 위한 절차나 방법을 공식화한 형태로 표현하는 것
  - 입력 데이터가 주어지면 일련의 행동을 거쳐 문제를 해결한 결과 데이터를 반환하는 것
- 알고리즘의 특징
  - **입력 데이터** : 주어진 입력 데이터를 인식할 수 있어야 함
  - **출력 데이터** : 유의미한 결과 데이터를 반환할 수 있어야 함
  - **유한성** : 일정 수의 처리 이후 정지해야 함
  - **유일성** : 알고리즘의 각 단계마다 명확한 단계를 가짐
  - **타당성** : 알고리즘을 구현할 수 있고 실용적이어야 함
- 컴퓨터비전 기술을 활용한 문제 해결 알고리즘을 구성할 때 고려해야 할 추가적인 사항
  - **복잡한 데이터 변환**
    - 컴퓨터비전에서는 데이터가 다차원이며 현실 세계와의 직접적인 관계가 복잡함
    - 데이터 변환 과정에서 발생하는 문제 고려
  - **불확실성과 노이즈**
    - 실제 환경에서 획득되는 데이터는 노이즈를 포함하고 불완전할 수 있음
    - 알고리즘은 이러한 불확실성을 처리하거나 제거할 수 있는 강건한(Robust) 방식을 가져야 함
  - **대량의 데이터 처리**
    - 대부분의 컴퓨터비전 알고리즘은 많은 양의 데이터를 처리해야 함
    - 처리 속도와 메모리 사용량 고려
  - **실시간 처리**
    - 컴퓨터비전 기술은 다양한 분야에서 실시간 요구사항을 가질 수 있음
    - 알고리즘의 처리 속도와 실시간 성능도 고려되어야 함
  - **딥러닝 모델**
    - 최근 컴퓨터비전에서는 전통적인 이미지 처리 방식 이외에도 딥러닝 모델이 많이 사용됨
    - 이러한 모델은 수많은 매개 변수를 가지고 복잡한 특징을 학습함
    - 해결하는 문제에 따라 딥러닝 모델 도입 고려
- 컴퓨터비전 알고리즘을 활용하는 주된 두 가지 관점
    1. 인간의 시각을 모방하거나 재현해 인공 시각 개발
        - 인간의 시각 원리를 컴퓨터비전에 적용해 인간과 유사한 시각 능력을 갖춘 시스템 구축
        - 시각 정보는 유동적으로 처리되므로 인공지능과 밀접한 관련이 있음
    2. 한정된 입력 데이터 내에서 특정한 목적을 수행하는 인공 시각 개발
        - 특정 상황에서 고정된 임무를 수행하여 실용적인 시스템 구성
        - 주로 사람의 시각으로는 식별하기 어려운 문제를 다루거나 단순 반복적인 문제를 해결하는 데 사용
- 컴퓨터비전 알고리즘이 수행되는 대략적인 과정
    1. **입력 데이터 수집** : 이미지 또는 영상과 같은 입력 데이터 수집
    2. **전처리 과정**
        - 수집한 데이터를 분석 가능한 형태로 변환하기 위해 전처리 수행
        - 노이즈 제거, 크기 조정, 색상 보정 등의 작업이 수행됨
    3. **특징 검출**
        - 변환된 데이터에서 중요한 특징 검출
        - 예: 윤곽선, 코너, 데이터 영역 내의 특성과 같은 특징을 검출하고 벡터화하는 작업 수행
    4. **데이터 해석**
        - 특징을 추출한 데이터를 분석해 문제 해석
        - 추출한 특징이 어떤 정보를 가지고 있는지 해석하며, 이를 토대로 문제 해결에 활용할 방법 결정
        - 문제 해결을 위해 적합한 알고리즘을 선택하고 적용함
        - 데이터 해석을 바탕으로 알고리즘을 조정하고 결정함
    5. **출력 데이터 생성**
        - 알고리즘이 실행되고 나면 원하는 결과물 생성
        - 이 결과물은 사용자가 원하는 형식에 맞게 변환됨
- 컴퓨터비전 알고리즘은 입력 데이터를 받아 전처리하고, 특징을 검출하며, 데이터를 해석하고 알고리즘을 적용함
  - 최종적으로 출력 데이터를 생성하는 과정을 거치게 됨
  - 이러한 단계를 통해 복잡한 입력 데이터로부터 의미 있는 정보를 추출함

### 1. 문제 해결을 위한 선행 조건

- 다양한 수학 분야, 선형 대수학, 미적분, 영상 기하학, 통계학 등 넓은 범위의 수학적 개념이 필수적으로 요구됨
- 특히 선형 대수학과 미적분: 낮은 수준의 이미지 처리에 중요한 역할을 함
- 컴퓨터비전은 수학적 기반 위에 다양한 알고리즘과 기술이 구축됨
  - 이를 통해 이미지나 영상 데이터로부터 의미 있는 정보를 추출하고 처리할 수 있음
- 서로 다른 알고리즘에 대해 입력 데이터와 출력 데이터가 동일해도 내부적으로 적용되는 알고리즘이 다를 수 있음
- 인식이나 인지 영역의 경우 더 수준 높은 알고리즘이나 접근 방식이 필요함
  - 통계, 머신러닝의 원리를 이해하는 것이 중요함
  - 고성능 알고리즘을 개발하기 위해 심층학습 기술인 CNN, ViT, Panoptic Segmentation 등을 적용하기도 함
- 이미지는 배열 형태의 행렬로 구성됨
  - 효율적인 데이터 처리를 위해서는 데이터 구조와 탐색 기술, 특히 트리 구조에 대한 이해와 활용 능력 필요
- OpenCV는 컴퓨터비전 작업에 필요한 다양한 요구사항을 지원하며, 이미지 처리에 필요한 다양한 기능을 제공함

### 2. 하드웨어와 소프트웨어의 선택

- 복잡한 문제를 해결하는 소프트웨어는 대량의 연산과 복잡한 알고리즘을 처리해야 하기 때문에 우수한 성능의 하드웨어가 필수적
- 영상 처리에서 하드웨어는 컴퓨터의 성능과 카메라의 품질을 의미함
- 소프트웨어는 영상 처리를 위한 알고리즘과 프로그램을 의미함
- 정확한 알고리즘을 구현해야 하기 때문에 하드웨어의 성능이 좋다고 해서 알고리즘의 결과도 덩달아 좋아지는 것은 아님
- 효율적인 프로그램 설계와 개발을 위한 고려사항
  - 프로그램의 목적과 수행 역할을 명확하게 이해
  - 선택한 하드웨어와 소프트웨어 사이의 호환성 검토
  - 사용 범위

### 3. 시스템 설계

- 알고리즘을 설계하기 전, 고려해야 할 유형과 문제점을 명확하게 이해하면 개발 기간을 단축하고 비용을 낮출 수 있음
- 컴퓨터비전 시스템의 기본 설계 과정
    1. 문제점 인식: 작업 환경과 작업 요구사항을 정확하게 이해하는 것
    2. 데이터 분석
        - 처리해야 할 제품의 형태나 특징 등을 수집해 데이터베이스화
        - 활용 가능한 데이터 확인 :arrow_right: 시스템 구성
    3. 알고리즘
        - 컴퓨터비전의 기본적인 프로세스를 따라가며 입력 데이터를 전처리해 정제하고 특징 검출
    4. 성능 평가
        - 테스트 진행
        - 알고리즘의 성능, 효율성을 평가할 수 있음
        - 데이터베이스를 활용해 실험을 진행하거나 인식 성능을 테스트하는 절차 수행

### 4. 개발 규칙

- 안정성이 높고 효율적인 코드로 구성
- 보안성, 유용성, 확장성 등 외적인 요소와 함께 일관된 코드 패턴과 함께 코드의 변경 및 관리 등이 용이해야 함
- 명명 규칙
    1. 변수명이나 클래스명은 직관적으로 이해할 수 있게 선언하며 사전에 협의된 패턴의 형태로 작성한다.
    2. 이미 존재하는 예약어를 변숨녕이나 클래스명으로 사용하지 않는다.
    3. 코드의 확장성을 위해 특정한 데이터 형식(`int`, `double` 등)을 표기하지 않는다.
    4. 패키지나 라이브러리 등 사전에 정의된 이름은 사용하지 않는다.
    5. 가능한 한 혼동하기 쉽거나 비슷한 변수명은 사용하지 않는다.
- 레이아웃 규칙
    1. 들여쓰기는 탭 간격(4칸 띄어쓰기)을 활용한다.
    2. 함수 또는 메서드의 정의 사이에 하나 이상의 줄바꿈을 추가한다.
    3. 괄호를 적절히 활용해 표현식의 코드 절을 직관성 있게 구성한다.
    4. 코드는 최대한 간결하고 명료하게 작성한다.
    5. 예외 처리 시 어떤 예외를 처리했는지 구분해서 처리한다.
- 주석 규칙
    1. 함축적인 단어를 활용해 표시되는 정보를 간결하게 표현한다.
    2. 코드의 의도를 정확하게 표현한다.
    3. 쉽게 이해할 수 있는 코드에 대해서는 설명하지 않는다.
    4. 경고 사항이나 결함 사항을 표시한다.
    5. 입출력 예시를 설명한다.

## 03 디지털 이미지 프로세싱

- **디지털 이미지 프로세싱(Digital Image Processing)**
  - 디지털 이미지를 신호로 간주하고 처리하는 분야
  - 이미지로부터 의미 있는 정보를 추출하기 위해 사용되는 알고리즘
  - 변환, 분류, 탐지, 인식, 검출, 분석, 왜곡 보정, 수정, 향상, 복원, 압축, 필터링 등의 다양한 작업 포함
- 일반적으로 디지털 이미지는 2차원으로 표현
  - 각각의 배열 요소는 해당 위치의 **픽셀(Pixel)** 값을 나타냄
  - 픽셀은 이미지의 가장 작은 단위의 구성 요소
  - 픽셀 값들이 모여 이미지가 형성됨
  - 배열 요소는 개별 픽셀 값을 나타내며, 이 값들이 색상 정보를 표현함
- 인식, 분석, 조작
  - 인식
    - 육안으로는 식별하기 어려운 영역에서 차이점 발견
    - 다른 이미지나 영상과 비교해 특징을 찾아내는 것
  - 분석
    - 이미지 프로세싱을 통해 보정 및 변형된 이미지에서 특징을 추출하는 작업
  - 조작
    - 이미지를 보정하거나 원하는 정보를 얻기 위해 변형하는 것
    - 전처리 과정에서 이러한 작업이 가장 많이 이루어짐
    - 전체 이미지 프로세싱 과정에서 중요한 부분

### 1. 전처리 알고리즘

- 이미지에서 유의미한 정보를 추출하려면 데이터 정제나 불필요한 데이터를 제거하는 과정이 필수적
- 전처리 알고리즘: 불필요한 정보를 제거해 특정 알고리즘에서 활용 가능한 형태로 변환하는 과정
- 전처리 과정 종류
  - **이미지 크기 조정** : 이미지를 적절한 크기로 조절해 데이터 크기를 규격화한다.
  - **이미지 밝기 조정** : 이미지의 밝기와 대비를 조절해 데이터 품질을 향상시킨다.
  - **이미지 픽셀 조정** : 이미지 속 특정 패턴을 강조하거나 특정 임계값 이상 또는 이하의 값을 변경한다.
  - **노이즈 제거** : 이미지에서 불필요한 노이즈를 제거해 정확도를 향상시킨다.
  - **이미지 정규화** : 알고리즘에서 일관된 입력을 받을 수 있도록 색상 범위나 데이터 형식을 변경한다.
  - 이외에도 매우 다양한 전처리 알고리즘이 존재함
- 전처리 알고리즘은 데이터 상태와 목적에 따라 다양하게 조합되어 활용될 수 있음
- 올바르게 수행하지 않으면 오히려 부정적인 영향을 미칠 수 있음

### 2. 노이즈 및 디노이즈

#### 노이즈(Noise)

- 알고리즘 및 데이터 처리 수행 과정에서 원하지 않는 정보나 왜곡된 정보
- 화면의 변화, 피사체의 움직임, 카메라의 성능, 센서의 한계 등 다양한 이유로 발생 가능
- 형태와 원인에 따라 크게 다음과 같이 나뉨
  - **고정 패턴 노이즈(Fixed-Pattern Noise)**
    - 반복적인 패턴이나 일정한 간격으로 나타나는 노이즈
    - 각 픽셀마다 고유하게 발생
    - 고정된 조건에서는 항상 동일한 형태로 나타남
  - **무작위 노이즈(Random Noise)**
    - 불규칙한 노이즈
    - 이미지 센서나 환경적인 요인에 의해 발생
    - 주로 불규칙한 패턴 또는 색상의 변화로 나타남
  - **시간적 노이즈(Temporal Noise)**
    - 시간에 따라 변하는 노이즈 패턴
    - 주로 영상에서 발생
    - 객체의 움직임이나 빛의 변화로 인한 불규칙한 변화로 나타남
  - **양자화 노이즈(Quantization Noise)**
    - 아날로그 신호를 디지털로 변환할 때 발생하는 노이즈
    - 변환 과정에서 정밀도가 손실되어 발생
  - **압축 노이즈(Compression Noise)**
    - 이미지 파일의 용량을 줄이기 위해 압축 알고리즘을 적용했을 때 발생하는 노이즈
- 노이즈는 데이터에 부정확한 정보를 추가하거나 혼입시키게 되어 알고리즘의 정확성과 신뢰성을 저하시킴
- 노이즈를 고려하지 않고 데이터를 처리하면 원래의 정보가 왜곡되어 분석이나 예측에 큰 영향을 미침

#### 디노이즈(Denoise)

- 이미지나 신호에서 원치 않는 노이즈를 제거하는 과정
- 이미지 촬영, 전송, 압축될 때 발생할 수 있는 다양한 유형의 노이즈를 줄이는 데 사용됨
- 특정 패턴이나 주파수 구성 요소를 강조하거나 억제하는 필터링 기술을 적용할 수 있음
- Blurring, Sharpening, 특정 영역 내의 데이터를 비교하고 대체하는 다양한 연산 등이 포함됨
- 데이터 품질을 향상시키고 관심 있는 정보를 더 명확하게 만드는 과정
  - 노이즈가 포함되지 않은 이상적인 데이터라도 거시적 관점에서 검출에 방해하는 요소는 노이즈로 간주할 수 있음
- 관심 있는 정보를 뚜렷하게 하기 위해 불필요한 데이터를 제거하는 과정

### 3. 특징 및 유사성 검출

#### 특징 검출(Feature Detection)

- 이미지 내에서 주요한 부분을 식별하고 추출하는 과정
- 특징점의 정확한 위치를 식별하고 표시해 특정 객체 또는 패턴의 위치를 검출하거나 특징점을 시각적으로 부각시켜 해당 특징이 더 잘 강조되도록 만드는 방법
- 다음과 같은 속성을 사용해 파악 가능
  - **색상 강도(Color Intensity)** : 픽셀의 색상 밝기 또는 색상 정보를 분석해 식별
  - **연속성(Continuity)** : 주변 픽셀과 연속되거나 일정한 패턴을 감지해 식별
  - **변화량(Variation)** : 주변 픽셀 간의 밝기 변화를 감지해 식별
  - **의존성(Dependency)** : 주변 픽셀과의 관계나 의존성을 고려해 식별
  - **유사성(Similarity)** : 이미지 내 유사한 패턴 또는 구조로 파악
  - **임계점(Threshold)** : 일정 임곗값을 설정해 해당 임곗값을 초과하는 지점으로 파악

#### 유사성 검출(Similarity Detection)

- 이미지 내에서 유사한 영역을 검출하거나 강조하는 방법
- 이미지 간 유사도를 계산하는 방법
  - 주로 이미지 비교 및 검색 엔진에서 사용
  - 사용자가 특정 이미지를 제공하면 시스템은 이미지 데이터베이스에서 비슷한 이미지를 찾아내거나 이미지의 유사도를 순위로 매길 수 있음
- 이미지 내의 객체의 유사도를 계산하는 방법
  - 주로 객체 인식 및 분류에 사용됨
  - 이미지 내에서 서로 다른 객체나 영역 간의 유사성을 판단하거나, 동일한 객체의 다양한 변형을 감지하는 데 활용

## 04 영상 처리 분야

다음은 영상 처리가 활용되는 주요 분야

- 영화 산업
- 의료 분야
- 이미지 번역

### OpenCV의 활용

OpenCV는 영상 인식, 검출, 변환, 필터링, 특징 추출 및 추적 등을 지원해 다양한 응용 분야에서 유용하게 사용됨
