# 이미지 검출

- 영상 내에서 주요한 **특징(Feature)** 을 검출하는 방법
- 특징점이 존재하는 위치를 알려주거나 해당 특징점 부각
  - 이 특징은 이미지 내에서 다른 부분과 구별되는 고유한 특성을 가지고 있어 객체나 패턴을 식별하고 추적하는 데 사용됨
- 픽셀의 색상 강도, 연속성, 변화량, 의존성, 유사성, 임계점 등으로 특징을 파악해 윤곽선(Contours), 직선(Line), 원(Circle) 등 검출
- 이미지 내에서 중요한 지점 또는 패턴을 검출해 이미지 간 유사성을 판단하고 객체를 식별하는 데 활용됨

## 01 윤곽선 검출

- 전처리가 진행된 이미지에서 가장자리로 검출된 픽셀을 대상으로 **세그멘테이션(Segmentation)** 작업을 진행함
- 윤곽선 검출 과정 중 가장 중요한 요소는 검출하기 좋은 상태의 이미지로 만드는 것
  - 노이즈 제거를 진행하지 않았다면 노이즈 또한 윤곽선으로 인식되어 세그멘테이션을 진행할 때 불필요한 정보가 포함될 수 있음
  - 이미지 전처리 단계에서 노이즈 제거와 향상된 경계 감지 기술을 사용해 이미지 품질을 향상시키는 것이 중요
- 그 다음으로 중요한 요소는 윤곽선 검색 방법과 근사 방법을 선택하는 것
  - 검색 방법과 근사 방법에 따라 반환되는 윤곽선 형식이 크게 달라짐
  - 검색 방법: 윤곽점들의 세그멘테이션 방법 결정, 어떤 윤곽선을 검출할지에 영향을 미침
  - 근사 방법: 모든 윤곽선에 대한 윤관점을 반환하거나 검출된 윤곽점을 압축해 강도가 높은 윤곽점만 반환하는 방식 결정
- 마지막으로 윤곽선의 계층 구조를 고려해야 함
  - 검색 방법에 따라 게층 구조가 달라지며 계층 구조의 윤곽선들이 어떻게 연결되고 분리되는지 확인 가능
  - 계층 구조는 객체의 내부 및 외부 윤곽선을 구별하고 객체 간의 관계를 파악할 수 있음

### 1. 계층 구조

- 세그멘테이션이 어떻게 분류되었는가에 대한 정보가 담김
- 기본적으로 **트리(Tree)** 구조의 형태
  - 그래프의 일종
  - 여러 **노드(Node)** 가 한 노드를 가리킬 수 없는 구조
- 윤곽선 계층 구조의 노드는 세그멘테이션된 윤곽선 그룹군을 의미함
- **루트 노트(Root Node)**: 최상위 노드
- **부모 노드(Parent Node)**, **자식 노드(Child Node)**
- **잎 노드(Leaf Node)**: 자식 노드가 없는 노드
- **내부 노드(Internal Node)**: 잎 노드가 아닌 모든 노드
- 윤곽선 계층 구조는 색인 값으로 계층을 나눔
- 계층 구조에서 반환되는 값은 **다음 윤곽선**, **이전 윤곽선**, **자식 윤곽선**, **부모 윤곽선**
  - 다음 윤곽선과 이전 윤곽선: 같은 계층 선상에 있는 노드
- 자식 노드가 여러 개인 경우 동일 계층의 노드를 표현하는 다음 윤곽선과 이전 윤곽선을 추적해 해당 노드 간의 계층 구조 파악 가능
- 트리 구조 특성상 한 노드의 부모 노드는 하나이므로 자식 노드에서 해당 부모 노드 확인 가능
- 계층 구조를 통해 윤곽선 및 윤곽선 내부의 홀을 정확히 식별 가능

### 2. 데이터 추출

- 윤곽선 검출 함수의 주요 매개 변수: 검색 방법과 근사 방법
- 검색 방법: 윤곽선의 계층 구조를 결정하는 데 중요한 역할
- 근사 방법: 윤곽선들의 윤곽점 형태와 개수에 영향을 미침
- 윤곽선 검출 함수
  - C#

    ```csharp
    Cv2.FindContours(
        Mat image,
        out Point[][] contours,
        out HierarchyIndex[] hierarchy,
        Retr ievalModes mode,
        ContourApproximationModes method,
        Point? offset = null
    );
    ```

  - Python

    ```python
    contours, hierarchy = cv2.findContours(
        image,
        mode,
        method,
        offset=None
    )
    ```

  - 전처리가 진행된 **입력 이미지(`image`)** 에서 **검출된 윤곽선(`contours`)** 과 **계층 구조(`hierarchy`)** 반환
  - **검색 방법(`mode`)**: 윤곽선을 검출해 어떤 계층 구조의 형태를 사용할지 설정
  - **근사 방법(`method`)**: 윤곽점의 표시 방법 설정
    - 근사 방법에 따라 **검출된 윤곽선(`contours`)** 에 포함될 좌표의 수나 정교함의 수준이 달라짐
  - **오프셋(`offset`)**: 반환된 윤곽점들의 좌표값에 이동할 값 설정
    - 관심 영역에서 윤곽선을 검출하거나 다른 이미지에 표시하고자 할 때 주로 활용

  (표 6.1)

  - 각 검색 방법 플래그의 특징
    - `External`(`RETR_EXTERNAL`)
      - 최외곽 윤곽선만 검색
      - 내부의 홀이나 내부 윤곽은 검출 안함
      - 계층 구조의 형태: 부모 노드와 자식 노드는 모두 -1의 값을 가짐
    - `List`(`RETR_LIST`)
      - 모든 윤곽선 검출
      - 계층 구조를 형성하지 않음
      - 최외곽 윤곽선 검출 방식과 계층 구조는 동일한 형태를 가지나 내부의 홀이나 내부 윤곽 검출
    - `CComp`(`RETR_CCOMP`)
      - 모든 윤곽선을 검출
      - 2단계 계층 구조만 형성
        - 내부의 홀 안에 있는 윤곽은 상위 내부의 홀을 부모 노드로 가지지 않음
    - `Tree`(`RETR_TREE`)
      - 모든 윤곽선 검출
      - 트리 구조 형태로 계층 구조 형성

  (표 6.2)

  - 각 근사 방법 플래그의 특징
    - `ApproxNone`(`CHAIN_APPROX_NONE`)
      - 검출된 윤곽선의 모든 윤곽점들을 좌표값으로 반환
      - 반환된 좌표값을 중심으로 8개의 이웃 중 하나 이상의 윤곽점들이 포함됨
    - `ApproxSimple`(`CHAIN_APPROX_SIMPLE`)
      - 검출된 윤곽점에서 중복되는 픽셀을 제거해 최대한 윤곽선을 그릴 때 필요한 성분만 남김
      - 수평, 수직, 대각선 부분의 좌표값들을 압축해 끝 지점들만 남김
    - `ApproxTC89L1`(`CHAIN_APPROX_TC89_L1`)과 `ApproxTC89KCOS`(`CHAIN_APPROX_TC89_KCOS`)
      - Teh-Chin 알고리즘을 적용해 반환되는 좌표값을 줄이고 더 정교한 방식으로 반환
      - 이 알고리즘은 추가적인 매개 변수를 요구하지 않음

### 3. 윤곽선 그리기

- C#

  ```csharp
  Cv2.DrawContours(
      Mat image,
      IEnumerable<IEnumerable<Point>> contours,
      int contourIdx,
      Scalar color,
      int thickness = 1,
      LineTypes lineType = LineTypes.Link8,
      IEnumerable<HierarchyIndex> hierarchy = null,
      int maxLevel = int.MaxValue,
      Point? offset = null
  );
  ```

- Python

  ```python
  cv2.drawContours(
      image,
      contours,
      contourIdx,
      color,
      thickness=None,
      lineType=None,
      hierarchy=None,
      maxLevel=None,
      offset=None
  )
  ```

  - **이미지(`image`)**: 그릴 이미지
  - **윤곽선(`contours`)**: 검출된 윤곽선
  - **윤곽선 번호(`contourIdx`)**
    - 설정하면 지정된 윤곽선만 그릴 수 있음
    - 음수 값을 입력하면 모든 윤곽선을 그림
  - **색상(`color`)**, **두께(`thickness`)**, **선형 타입(`lineType`)**: 그리기 함수와 동일한 역할
  - **계층 구조(`hierarcy`)**: 윤곽선 검출 함수에서 반환된 계층 구조
  - **계층 구조 최대 레벨(`maxLevel`)**
    - 이미지에 그려질 윤곽선 계층 구조의 깊이
    - 0으로 설정할 경우 최상위 레벨만 그려짐
  - **오프셋(`offset`)**
    - 윤곽선 검출 함수에서 사용되는 오프셋 기능과 동일한 역할
    - 그려지는 이미지가 여러 곳일 때 활용

(예제 6.1)

- 전처리 수행 :arrow_right: 윤곽선 검출 :arrow_right: 윤곽선, 윤곽점 이미지 위에 표시한 예
- 노이즈를 제거하기 위해 이진화 적용
- 모폴로지 연산을 통해 스펙클 제거
- **반전 연산(`Cv2.BitwiseNot`)** 을 수행하는 이유: 윤곽선 함수가 흰색 픽셀들을 대상으로 검출하기 때문
  - 배경이 흰색일 경우 이미지의 테두리를 윤곽으로 검출함
- 모든 윤곽선을 검출해 트리 구조를 형성하고 Teh-Chin 알고리즘을 적용해 윤곽점을 더 정교한 지점만 남김

(예제 6.2)

- Python OpenCV의 윤곽선 계층 구조는 2차원이 아닌 3차원 형태로 반환함
  - 한 번 더 계층 구조를 감싸기 때문에 예제와 같이 `hierarchy[0][i][j]`의 형태로 접근

### 4. 다각형 근사

- 검출된 윤곽선의 형상을 분석할 때 해당 형상을 정점 수가 적은 다각형으로 근사하여 표현하는 방법
- 윤곽선 검출 함수에서 반환된 윤곽선 정보를 활용해 윤곽선의 복잡성을 낮추고 더 간결한 형태로 표현하여 데이터 단순화 가능
- 윤곽선의 정점 수를 줄였을 때의 효과
  - 해당 윤곽선을 저장하고 처리하는 데 필요한 메모리 및 계산 리소스 감소
  - 윤곽선에서 작은 노이즈나 불필요한 디테일을 제거해 더 명확하고 신뢰성 있는 데이터 확보 가능
- **더글라스-패커(Douglas-Peucker)** 알고리즘을 사용해 근사함
  - 선분으로 구성된 윤곽선을 더 적은 수의 윤곽점으로 동일하거나 비슷한 형태로 **데시메이트(Decimate)**함
    - 데시메이트: 일정 간격으로 샘플링된 데이터를 기존 간격보다 더 큰 샘플링 간격으로 다시 샘플링하는 것
  - 더글라스-패커 알고리즘의 주요 단계
      1. 시작과 끝점 선택
          - 초기 윤곽선에서 시작점과 끝점 선택
      2. 최대 편차 계산
          - 초기 윤곽선상에서 각 점과 시작점, 끝점을 연결하는 선분 중에서 최대 편차를 가진 점을 검출함
      3. 최대 편차와 근사치 정확도 비교
          - 최대 편차를 근사치 정확도와 비교
          - 최대 편차가 근사치 정확도보다 작거나 같다면 해당 선분은 근사 대상에서 제외
          - 최대 편차가 근사치 정확도보다 높다면 해당 선분의 중간 점을 선택해 윤곽선의 후보 점으로 추가
      4. 재귀 반복
          - 알고리즘은 시작점부터 최대 편차가 근사치 정확도보다 큰 선분까지 재귀적으로 반복해 근사를 수행함
  - **근사치 정확도(Epsilon)** 를 사용해 기존 다각형과 윤곽점이 압축된 다각형 간의 최대 편차를 고려해 다각형 근사
- 다각형 근사 함수
  - C#

    ```csharp
    Point[] approxCurve = Cv2.ApproxPolyDP(
        IEnumerable<Point> curve,
        double epsilon,
        bool closed
    );
    ```

  - Python

    ```python
    approxCurve = cv2.approxPolyDP(
        curve,
        epsilon,
        closed
    )
    ```

  - 하나의 다각형에 대해 근사가 가능함
  - **윤곽선(`curve`)**: 윤곽선 검출 함수에서 검출된 하나의 윤곽선을 활용하거나 배열로 구성된 다각형 윤곽점 사용
  - **근사치 정확도(`epsilon`)**
    - 입력된 다각형과 반환될 근사화된 다각형 사이의 최대 편차 간격 의미
    - 작을 수록 기존 형태와 비슷함
  - **폐곡선(`closed`)**: 시작점과 끝점의 연결 여부
    - `True`: 마지막 점과 첫 번째 점이 연결됨

(예제 6.3)

- 윤곽선 검출 예제에 다각형 근사 함수 추가
- 다각형 근사 함수에서 가장 중요한 매개 변수는 **근사치 정확도(`epsilon`)**
  - 여기에 적절한 값을 주기 위해 곡선 길이(`Cv2.ArcLength`) 함수를 사용해 윤곽선의 전체 길이를 계산
  - 이 함수의 매개 변수는 단일 윤곽선과 폐곡선 여부를 설정함

(예제 6.4)

### 5. 윤곽선 정보

- 윤곽선: 이미지나 비디오에서 물체의 경계를 나타내는 중요한 정보 제공
  - 이 정보를 활용해 물체의 형태, 크기, 방향 및 다양한 특성 추출 가능
- 윤곽선의 기하학적 특징을 분석하여 물체의 식별이나 추적, 영상 처리 작업에서 유용한 정보 도출 가능
- 윤곽선 정보를 분석하는 데 사용되는 몇 가지 기본 작업
  - 물체의 면적 계산, 중심 좌표 추출, 경계 상자 생성, 물체의 회전 각도 계산, 윤곽선 주변의 특정 영역 분석 등

#### 곡선 길이

- C#

  ```csharp
  double length = Cv2.ArcLength(
    IEnumerable<Point> curve,
    bool closed
  );
  ```

- Python

  ```python
  length = cv2.arcLength(
      curve,
      closed
  )
  ```

- **윤곽선(`curve`)** 의 길이 계산
- 매개 변수로 입력되는 윤곽선: 곡선의 형태를 지닌 배열이나 벡터의 형태로 간주됨
- **폐곡선(`closed`)**: 윤곽선의 닫힘 여부
  - 닫힌 것으로 간주하면 마지막 지점과 첫 번째 지점 연결
  - 윤곽선의 닫힘 여부에 따라 반환되는 **길이(`length`)** 의 값이 달라짐

#### 면적 계산

- C#

  ```csharp
  double area = Cv2.ContourArea(
    IEnumerable<Point> contour,
    bool oriented = false
  );
  ```

- Python

  ```python
  area = cv2.contourArea(
      contour,
      oriented
  )
  ```

- **윤곽선(`curve`)** 내부의 면적 계산
- 매개 변수로 입력되는 윤곽선: 곡선의 형태를 지닌 배열이나 벡터의 형태로 간주됨
- **방향성(`oriented`)**: 계산된 윤곽선 면적의 부호 의미
  - `True`: 윤곽선의 방향(시계, 반시계 방향)에 따라 부호가 있는 면적 값으로 반환
  - `False`: 절대값으로 계산된 면적 값 반환

#### 경계 사각형

- C#

  ```csharp
  Rect boundrect = Cv2.BoundingRect(
    IEnumerable<Point> curve
  );
  ```

- Python

  ```python
  boundrect = cv2.boundingRect(
      curve
  )
  ```

- **윤곽선(`curve`)** 의 경계면을 둘러싸는 사각형 반환
- 반환 결과
  - 회전이 고려되지 않은 직사각형 형태
  - 경계면의 윤곽점들을 둘러싸는 최소 사각형의 형태
  - C#: 직사각형 구조체 형태 / Python: `(x, y, width, height)`의 형태

#### 최소 면적 사각형

- C#

  ```csharp
  RotatedRect rect = Cv2.MinAreaRect(
    IEnumerable<Point> points
  );
  ```

- Python

  ```python
  rect = cv2.minAreaRect(
      points
  )
  ```

- **윤곽선(`points`)** 의 경계면을 둘러싸는 최소 크기의 사각형 반환
- 반환 결과
  - 회전을 고려한 직사각형 형태
  - 경계면의 윤곽점들을 둘러싸는 회전된 최소 직사각형의 형태
  - C#: 회전 직사각형 구조체 형태 / Python: `((centerX, centerY), (width, height), angle)`의 형태

#### 최소 면적 원

- C#

  ```csharp
  Cv2.MinEnclosingCircle(
    IEnumerable<Point> points,
    out Point2f center,
    out float radius
  );
  ```

- Python

  ```python
  center, radius = cv2.minEnclosingCircle(
      points
  )
  ```

- **윤곽선(`points`)** 의 경계면을 둘러싸는 최소 크기의 원 반환
- 경계 사각형 함수와 비슷한 기능
- 윤곽점이 원 내부에 존재
- 반환 결과
  - **중심점의 좌표(`center`)** 와 **반지름(`radius`)** 를 가짐
  - C#: `out` 키워드를 통해 중심점과 반지름 반환 / Python: `(centerX, centerY), radius`의 형태

#### 타원 피팅

- C#

  ```csharp
  RotatedRect ellipse = Cv2.FitEllipse(
    IEnumerable<Point> points
  );
  ```

- Python

  ```python
  ellipse = cv2.fitEllipse(
      points
  )
  ```

- **윤곽선(`points`)** 의 집합에 대해 가장 근사한 타원 반환
- 윤곽점이 타원 밖에 존재할 수도 있음
- 반환 결과
  - 회전을 고려한 직사각형의 형태
  - C#: 회전 직사각형 구조체 형태 / Python: `((centerX, centerY), (axesWidth, axesHeight), angle)`의 형태

#### 볼록 껍질

- C#

  ```csharp
  Point[] hull = Cv2.ConvexHull(
      IEnumerable<Point> points,
      bool clockwise = false
  )
  ```

- Python

  ```python
  hull = cv2.convexHull(
      points,
      clockwise = None
  )
  ```

- **윤곽선(`points`)** 의 경계면을 둘러싸는 다각형 반환
- 반환 결과
  - 윤곽선 검출 결과와 동일한 형식
  - **방향(`clockwise`)**: 검출된 볼록 껍질의 볼록점들의 색인 순서
    - `True`: 시계 방향으로 정렬됨
    - `False`: 반시계 방향으로 정렬됨
- $`O\left(N\log{N}\right)`$ 시간 복잡도를 가지는 **스크랜스키(Sklansky) 알고리즘** 을 이용해 입력된 좌표들의 볼록한 외곽을 찾음

  <img src="../img/sklansky_convex.png" width="700">

  - 윤곽점에서 경계 사각형의 정점(Vertex) 검출
  - 경계면을 둘러싸는 다각형은 경계 사각형 내부에 포함되며, 해당 정점을 볼록점으로 사용함
  - 볼록 껍질의 또 다른 볼록점들은 $`R_{n}`$ 영역 내에 존재, $`Q`$ 영역에는 존재하지 않음
    - $`R_{1}, R_{2}, R_{3}, R_{4}`$ 내부에 있는 추가적인 볼록점들을 검출
    - $`R_{n}`$ 영역 내부에도 다양한 윤곽점들이 존재하므로 여기서 볼록 껍질을 이루는 볼록점들을 선별해 선택
    - 볼록점의 시작점이 $`P_{i}`$, 다음 번째 볼록점이 $`P_{i + 1}`$
      - $`P_{i}`$가 $`V_{left}`$인 경우 $`P_{i + 1}`$, $`P_{i + 2}`$를 검출하기 위해 다음과 같은 조건으로 볼록점 선택  
        (초기 $`P_{i + 1}`$은 입력된 윤곽점들의 $`P_{i}`$의 $`i + 1`$ 번째 사용)
        - $`P_{i + 2}`$의 점이 A 영역 내부에 있을 경우 $`P_{i + 2}`$ 점을 $`P_{i + 1}`$ 점으로 활용
        - $`P_{i + 2}`$의 점이 B 영역 내부에 있을 경우 $`P_{i + 2}`$ 점은 볼록점에서 제외
        - $`P_{i + 2}`$의 점이 C 영역 내부에 있을 경우 $`P_{i + 2}`$ 점을 볼록점으로 간주
      - 현재 처리하고 있는 정점의 위치에 따라 앞선 조건의 A, B, C 영역이 바뀜
        - $`V_{right}`$에서 $`V_{top}`$으로 진행되는 순서라면 A 영역은 Q 영역이 되어 볼록점에서 제외

#### 볼록성 시험

- C#

  ```csharp
  bool convex = Cv2.IsContourConvex(
      IEnumerable<Point> contour
  );
  ```

- Python

  ```python
  convex = cv2.isContourConvex(
      contour
  )
  ```

- 볼록성 시험 함수는 **윤곽선(`contour`)** 의 형태가 볼록한 형태를 지니고 있는지 확인함
  - 볼록한 형태는 윤곽선 형태가 볼록한 형태나 수직한 형태를 갖는 것을 의미함
  - 볼록한 경우 단순한 다각형 형태를 지니고 있다고 볼 수 있음: 교차하는 점이 없는 형태
- 윤곽선이 볼록하다면 `True`, 볼록하지 않다면 `False` 반환

#### 모멘트

- C#

  ```csharp
  Moments moments = Cv2.Moments(
      IEnumerable<Point> array,
      bool binaryImage = false
  );
  ```

- Python

  ```python
  moments = cv2.moments(
    array,
    binaryImage=None
  )
  ```

- **윤곽선(`array`)** 이나 **이미지(`array`)** 의 0차 모멘트부터 3차 모멘트까지 계산
- **이진화 이미지(`binaryImage`)** 는 입력된 `array` 매개 변수가 이미지일 경우 이미지의 픽셀 값들을 이진화 처리할지 결정
  - `True` 할당: 이미지의 픽셀 값이 0이 아닌 값은 모두 1의 값으로 변경해 모멘트 계산
- 수식 6.1 공간 모멘트(Spatial moments)  
  $`m_{i, j} = \underset{x, y}{\sum}\left( array\left( x, y \right) \times x^{i} y^{j} \right)`$
- 모멘트 $`m_{ij}`$는 윤곽선(이미지)의 모든 픽셀에 대한 합으로 정의됨
  - $`i`$와 $`j`$의 값에 따라 계수가 달라지며 단순하게 현재 픽셀에 해당하는 인수를 곱함
  - $`i = 0, j = 0`$의 모멘트를 계산하면 입력된 윤곽선(이미지) 픽셀들의 영역이 됨
  - $`m_{00}`$ 모멘트는 윤곽선(이미지)의 면적이 됨: 면적 계산 함수의 결과와 동일한 값 반환
  - $`m_{10}`$ 모멘트와 $`m_{01}`$ 모멘트를 각각 $`m_{00}`$ 모멘트로 나눈다면 윤곽선(이미지)의 평균 값을 얻을 수 있음
- 모멘트 함수를 사용하면 면적, 평균, 분산 등을 간단하게 구할 수 있음
- 모멘트 함수는 공간 모멘트 뿐만 아니라 중심 모멘트, 정규화된 중심 모멘트까지 구할 수 있음
- 수식 6.2 중심 모멘트(Central Moments)  
  $`mu_{i,j} = \underset{x, y}{\sum}\left( array\left( x,y \right) \times \left( x-\bar{x} \right)^{i} \left( y-\bar{y} \right)^{j} \right)`$
- 수식 6.3 정규화된 중심 모멘트(Normalized Central Moments)  
  $`nu_{i,j} = \dfrac{mu_{i,j}}{m_{00}\dfrac{\left( i + j \right)}{2} + 1}`$
- 수식 6.4 질량 중심(Mass Center)  
  $`\bar{x} = \dfrac{m_{10}}{m_{00}} \quad \bar{y}=\dfrac{m_{01}}{m_{00}}`$

- $`mu_{00}, mu_{10}, mu_{01}, nu_{00}, nu_{10}, nu_{01}`$은 항상 값은 값(0)을 갖게 되므로 반환하지 않음
- C#: 반환 형식이 `Moments`로, `moments.M00` 등으로 `dobule` 형식을 갖는 값으로 활용 가능
- Python: 사전 형식으로 `{'m00': 27530.0, ...}`의 구조로 반환
- 다음은 모멘트 함수에서 반환되는 모멘트
  - 0차 모멘트: $`m_{00}`$
  - 1차 모멘트: $`m_{10}`$, $`m_{01}`$
  - 2차 모멘트: $`m_{11}`$, $`m_{20}`$, $`m_{02}`$
  - 3차 모멘트: $`m_{21}`$, $`m_{12}`$, $`m_{30}`$, $`m_{03}`$
  - 2차 중심 모멘트: $`mu_{11}`$, $`mu_{20}`$, $`mu_{02}`$
  - 3차 중심 모멘트: $`mu_{21}`$, $`mu_{12}`$, $`mu_{30}`$, $`mu_{03}`$
  - 2차 정규화된 중심 모멘트: $`nu_{11}`$, $`nu_{20}`$, $`nu_{02}`$
  - 3차 정규화된 중심 모멘트: $`nu_{21}`$, $`nu_{12}`$, $`nu_{30}`$, $`nu_{03}`$

## 02 특징 검출

- Feature Detection
- 이미지 내의 주요한 특징점을 검출하는 방법
- 관심 있는 객체나 패턴을 식별하고 분석하는 데 사용
- 픽셀의 색상 강도, 연속성, 변화량, 의존성, 유사성, 임계점 등을 사용해 특징을 파악
  - 해당 특징점이 존재하는 위치를 알려주거나 해당 특징점 부각
- 특징 검출에 사용되는 주요 프로세스
  - 픽셀의 색상 강도
    - 이미지에서 각 픽셀의 색상 강도를 분석해 밝기 또는 명암 정보 추출 가능
    - 고주파나 저주파 성분 검출 가능
  - 연속성
    - 특정 패턴 또는 물체가 이미지에서 어떻게 연속되는지를 의미함
    - 연속성을 이용하면 객체의 경계나 외형 파악 가능
  - 변화량
    - 이미지에서 픽셀 값 또는 특정 특징의 변화량 감지
    - 주로 움직임을 검출하거나 객체의 윤곽을 추출하는 데 사용
  - 의존성
    - 특징 검출은 주변 픽셀 또는 특징과의 관계를 고려함
    - 주위 환경과의 상호 작용을 분석하는 데 사용
  - 유사성
    - 이미지 내에서 비슷한 패턴이나 특징을 찾아냄
    - 유사성을 이용하면 이미지 내에서 객체를 식별하거나 비슷한 패턴을 추출할 수 있음
  - 임계점
    - 특정 특징이나 객체를 식별하기 위한 임계값 설정
    - 임계값을 조절하여 특징 검출 성능 향상

### 1. 코너 검출

- Corner Detection
- 입력 이미지에서 코너점을 식별하는 알고리즘
- **트래킹(Tracking)** 하기 용이한 특정 지점을 코너로 정의
  - 코너는 추적 가능한 특징 지점이 되며, 이를 통해 다각형의 꼭지점을 검출하는 데 활용 가능
  - 다각형의 꼭지점이 추적하기 어려운 지점이라면 코너를 검출하는 것이 어려워짐
- 코너의 강도를 계산해 코너점 식별
  - 높은 도함수(강한 미분)를 가지는 지점인 가장 두드러진 코너점을 계산해 코너의 정의를 만족하는 지점 반환
- 지안보 시(Jianbo Shi)와 카를로 토마시(Carlo Tomasi)가 개선한 특징 검출 알고리즘과 해리스(Harris)가 제안한 알고리즘
- 객체 추적, 이미지 매칭, 구조화된 환경에서의 위치 결정 등 다양한 분야에서 활용
- 코너 검출 함수
  - C#

    ```csharp
    Point2f[] corners = Cv2.GoodFeaturesToTrack(
      Mat src,
      int maxCorners,
      double qualityLevel,
      double minDistance,
      InputArray mask,
      int blockSize,
      bool useHarrisDetector,
      double k
    );
    ```

  - Python

    ```python
    corners = cv2.goodFeaturesToTrack(
        image,
        maxCorners,
        qualityLevel,
        minDistance,
        mask=None,
        blockSize=None,
        useHarrisDetector=None,
        k=None
    )
    ```

  - 8비트 또는 32비트의 단일 채널 이미지를 **입력 이미지(`image`)** 로 사용해 **코너(`corners`)** 검출
  - **코너 최대값(`maxCorners`)**
    - 검출할 최대 코너의 수 제한
    - 0 이하의 값을 사용하면 최대 코너의 수를 제한하지 않음
    - 검출할 최대 코너의 수보다 더 많은 코너의 수가 검출된 경우 코너 강도가 약한 코너점은 반환하지 않음
  - **코너 품질(`qualityLevel`)**
    - 반환할 코너의 최소 품질 설정
    - 0.0 - 1.0 사이의 값으로 할당 가능
    - 일반적으로 0.01 - 0.10 사이의 값 사용
    - 코너 품질을 계산할 때 검출된 코너 중 가장 좋은 코너 강조를 갖는 측정 값에 코너 품질 수치를 곱한 값보다 낮은 값이면 해당 코너들은 무시
  - **최소 거리(`minDistance`)**
    - 검출된 코너들의 최소 근접 거리
    - 설정된 최소 거리 이상의 값만 검출
  - **마스크(`mask`)**
    - 입력 이미지와 같은 차원을 갖는 이미지(배열)
    - 마스크의 값이 0인 곳은 코너를 계산하지 않음
      - 선택적 관심 영역 설정
  - **블록 크기(`blockSize`)**
    - 코너를 계산할 때 고려하는 코너 주변 영역의 크기
    - 블록 크기 영역에 대해 고유 값과 고유 벡터를 계산함(공분산 행렬을 의미)
  - **해리스 코너 검출기(`useHarrisDetector`)**
    - 코너 강도를 게산하는 데 사용할 알고리즘
    - `True`: 해리스가 제안한 알고리즘 사용
    - `False`: 지안보 시와 카를로 토마시가 개선한 특징 검출 알고리즘 사용
  - **해리스 측정 계수(`k`)**
    - 해리스 알고리즘을 사용할 때 할당
    - 해리스 대각합의 감도 계수를 의미함
- 객체를 인식하기 위해 코너 검출 알고리즘을 사용한다면 더 정확한 코너점을 필요로 함
  - 정확한 위치로 계산하기 위해 근사 계산을 수행해 서브 픽셀의 코너 위치를 재조정함
- 코너 픽셀의 세밀화를 진행하면 검출된 코너점의 위치를 보정함
- 서브 코너 픽셀
  - 직교하는 두 벡터의 내적이 0이라는 원리를 기반으로 함
  - 코너점 주변의 기울기와 연관된 벡터를 하나로 묶어 내적이 0이라는 방정식을 추가해 0이 되는 위치를 보정된 위치로 사용
- 코너 픽셀 세밀화 함수
  - C#

    ```csharp
    Point2f[] corners = Cv2.CornerSubPix(
        Mat src,
        IEnumerate<Point2f> inputCorners,
        Size winSize,
        Size zeroZone,
        TermCriteria criteria
    );
    ```

  - Python

    ```python
    corners = cv2.cornerSubPix(
        image,
        corners,
        winSize,
        zeroZone,
        criteria
    )
    ```

  - `inputCorners`, `corners`는 코너 검출을 통해 얻어낸 정수 픽셀의 코너 위치를 담고 있는 배열
  - 서브 코너 픽셀의 실제 위치는 두 벡터의 내적이 0이 되는 조건을 사용하므로 정수 픽셀의 코너 위치를 중심으로 **검출 크기(`winSize`)** 의 크기만큼 확장
    - 검출 크기의 인수 값이 `(n, n)` 크기를 갖는 경우 **(`n×2+1, n×2+1`)** 의 크기로 영역 검색
    - 방정식은 자기 상관 행렬의 역행렬로 풀 수 있는 선형 시스템 구성
    - 역행렬로 구현할 수 있도록 인접한 픽셀을 고려하지 않음
  - **제외 크기(`zeroZone`)**
    - 검출 영역에서 제외하려는 부분의 크기 설정
    - **검출 크기(`winSize`)** 와 동일한 계산 방법 사용
    - `(-1, -1)`의 크기를 사용할 경우, 제외하려는 영역이 없음을 의미
  - **기준(`criteria`)**
    - 코너 픽셀 세밀화 반복 작업 조건 설정
    - 입력된 코너점이 보정된 코너점의 위치를 찾는 경우, 그 값을 추측 위치로 사용하며 설정된 기준에 도달할 때까지 반복해서 계산
    - 반복 종료 기준: 설정된 반복 횟수나 검출 정확도를 만족할 때

(예제 6.5)

- **그레이스케일 이미지(`gray`)** 를 활용해 코너 검출과 코너 픽셀 세밀화를 진행한 예
- 원 그리기 함수는 좌표에 정수형만 사용 가능하므로 시각적으로 확인하기 위해 정수형으로 변경
- 일반적으로 보정된 코너점은 다시 정수점으로 변경해 사용하지 않음

(예제 6.6)

- **그레이스케일 이미지(`gray`)** 를 활용해 코너 검출과 코너 픽셀 세밀화를 진행한 예
- 코너 픽셀 세밀화: Python에서는 C#에서와 다르게 인수로 사용된 코너점에 덧씌워짐
- `ravel`: 평탄화 함수 :arrow_right: 2차원 배열을 1차원으로 축소해 좌표를 반환함

### 2. 직선 검출

- Line Detection
- 이미지 내에서 선형적인 부분을 검출하기 위해 사용
- **허프 선 변환(Hough Line Transform)** 을 활용해 직선 검출: 이미지에서 직선을 검출하는 가장 보편적인 알고리즘
  - 이미지에서 선과 같은 단순한 형태를 빠르게 검출할 수 있어 직선을 찾아 이미지나 영상을 보정하거나 복원할 때 주로 사용
- 도로의 차선이나 건물의 외형 또는 이미지 내의 소실점 등을 검출하는 데 주로 활용
- 허프 선 변환 알고리즘 작동방식
  - 이미지의 각 점들을 검사하며 직선 위에 놓일 가능성이 있는 모든 점 확인
  - 이를 위해 각 점은 다양한 기울기와 원점 거리를 표현하는 허프 공간으로 변환됨
  - 허프 공간에서 특정 값을 가지는 점들은 같은 직선 위에 있는 것으로 간주됨
- 허프 선 변환은 이미지 내의 어떤 점이라도 선 집한의 일부일 수 있다는 가정 하에 직선의 방정식을 이용해 직선 검출
  - 삼각함수를 활용해 각 선을 극좌표($\rho$, $\theta$)의 점으로 변환해 나타냄
  - 수식 6.4 삼각 함수를 활용한 직선의 방정식  
    $`\rho = x \sin\theta + y \cos\theta`$
  - $`\rho`$: 직선과 원점의 거리
  - $`\theta`$: 직선과 x축이 이루는 각도
- 점 $`p_{n}`$에 대해 극좌표로 표현할 때 $\sin$ 함수의 형태로 표현됨
- 점 $`p_{1}`$과 $`p_{2}`$가 직선을 이루는 방정식일 때 각 거리($`\rho`$)와 각도($`\theta`$)는 같은 값을 가짐
  - 모든 점에 적용할 경우 $n$개의 방정식이 교차되는 지점이 직선일 확률이 가장 높은 지점이 됨
  - 교차하는 지점 수가 평면에서 누산되기 때문에 이 평면을 **누산 평면(Accumulator Plane)** 또는 누적 평면이라 부름
- 위의 원리를 활용해 이미지 내의 모든 점에 대해 극좌표로 변환한 후 같은 값의 $`\left( \rho, \theta \right)`$를 가지는 모든 점들을 누산 평면에 누적함
  - 이는 $`n`$개의 방정식이 교차하는 지점으로 생각할 수 있음
  - 이 교차 지점이 직선의 방정식을 나타내는 데 사용됨
- 누산 평면은 이미지에서 각 직선 방정식이 교차하는 위치를 표현하는 이차원 배열 또는 행렬이며, 이를 통해 직선 검출 가능
- 이미지에서 특정 값 또는 임계치 이상의 값을 갖는 위치는 직선을 의미
  - 누산 평면은 이를 식별하고 추출
  - 누산 평면의 좌표를 해석해 이미지상의 직선의 각도와 거리 측정 및 분석
- OpenCV의 허프 변환은 총 세 종류의 변환을 지원함
  - 표준 허프 변환: Standard Hough Transform
  - 멀티 스케일 허프 변환: Multi-Scale Hough Transform
  - 점진성 확률적 허프 변환: Progressive Probabilistic Hough Transform
- 허프 선 변환 함수
  - C#

    ```csharp
    LineSegmentPolar[] lines = Cv2.HoughSlines(
        Mat image,
        double rho,
        double theta,
        int threshold,
        double srn = 0,
        double stn = 0
    );
    ```

  - Python

    ```python
    lines = cv2.HoughLines(
        image,
        rho,
        theta,
        threshold,
        srn=None,
        stn=None,
        min_theta=None,
        max_theta=None
    )
    ```

    - 표준 허프 변환, 멀티 스케일 허프 변환 동시 지원: 매개 변수 사용 여부로 어떤 변환을 진행할지 선택
    - 표준 허프 변환은 앞에서 설명한 알고리즘, 멀티 스케일 허프 변환은 검출한 직선의 값이 더 정확한 값으로 반환되도록 개선한 방법
    - **입력 이미지(`image`)**
      - 8비트 단일 채널 이미지 사용
      - 일반적으로 이진화 함수나 캐니 에지 함수의 결과를 인수로 사용함
    - **거리(`rho`)**, **각도(`theta`)**
      - 누산 평면에서 사용되는 해상도
      - 거리의 단위는 픽셀, 0.0 - 1.0의 실수 범위
      - 각도의 단위는 라디안, 0 - 180의 범위
      - 각도×거리의 차원을 갖는 2차원 히스토그램으로 구성됨
    - **임계값(`threshold`)**
      - 허프 변환 알고리즘이 직선을 결정하기 위해 만족해야 하는 누산 평면의 값
    - `srn`, `stn`
      - 멀티 스케일 허프 변환을 활용할 때 사용되는 매개 변수
      - `srn`: 거리(`rho`)에 대한 약수
      - `stn`: 각도(`theta`)에 대한 약수
      - 거리와 각도는 정규화되지 않은 값이므로 멀티 스케일 허프 변환 알고리즘이 거리와 각도의 값을 조정하기 위해 `srn`과 `stn`을 사용함
      - 이 두 매개 변수는 직선에 대한 매개 변수를 계산하기 위한 해상도 조절을 의미함: `rho/srn`의 형태
      - 두 값 모두 0일 경우 표준 허프 변환이 적용됨
    - Python OpenCV에서는 추가로 `**최소 각도(`min_theta`)** 와 **최대 각도(`max_theta`)** 를 매개 변수로 활용 가능
      - 직선의 최소, 최대 각도 설정
      - 최소 각도는 0에서 최대 각도 사이의 값
      - 최대 각도는 최소 각도에서 $`\pi`$ 사이의 값
- 점진성 확률적 허프 변환
  - 또 다른 허프 변환 함수를 사용해 직선을 검출함
  - 임의의 점 일부만 누적해서 계산
  - 일부의 점만 사용하기 때문에 확률적
  - 정확도가 높은 입력 이미지에 대해 검출에 드는 시간이 대폭 줄어듦
  - 시작점과 끝점을 반환하므로 더 간편하게 활용 가능
- 확률 허프 선 변환 함수
  - C#

    ```csharp
    LineSegmentPolar[] lines = Cv2.HoughLinesP(
        Mat image,
        double rho,
        double theta,
        int threshold,
        double minLineLength = 0,
        double maxLineGap = 0
    );
    ```

  - Python

    ```python
    lines = cv2.HoughLinesP(
        image,
        rho,
        theta,
        threshold,
        minLineLength=None,
        maxLineGap=None
    )
    ```

  - 점진성 확률적 허프 변환만 지원
  - **입력 이미지(`image`)**, **거리(`rho`)**, **각도(`theta`)**, **임계값(`threshold`)**: 허프 선 변환 함수와 동일한 의미
  - **최소 선 길이(`minLineLength`)**
    - 검출된 직선이 가져야 하는 최소한의 선 길이
    - 이 값보다 낮은 경우 직선으로 간주하지 않음
  - **최대 선 길이(`maxLineLength`)**
    - 검출된 직선들 사이의 최대 허용 간격
    - 이 값보다 간격이 좁은 경우 직선으로 간주하지 않음: 선분 간 결합 방지

(예제 6.7)

- 간단하게 전처리가 진행된 이미지에 점진성 확률적 허프 변환 방식을 적용한 예
- 허프 선 변환은 기본적으로 모든 점에 대해 직선의 방정식을 행성하므로 최대한 점의 성분을 제거함
  - 이때 그레이스케일, 이진화, 모폴로지 연산을 차례대로 적용
  - 모폴로지 연산을 활용해 노이즈 성분 최대한 제거
  - 노이즈가 대부분 제거된 상태에서 캐니 에지를 적용해 가장자리 선분만 남김
    - 캐니 에지 매개 변수의 임계값은 이진화가 처리된 이미지에 적용해서 큰 의미가 없음

(예제 6.8)

- 간단하게 전처리가 진행된 이미지에 멀티 스케일 허프 변환을 적용한 예
- 허프 선 변환 함수는 시작점과 도착점을 알려주는 게 아니라, 가장 직선일 가능성이 높은 거리와 각도를 검출함
  - 검출된 정보는 직선의 방정식에 더 가까움

### 3. 원 검출

- Circle Detection
- **허프 원 변환(Hough Circle Tranfsorm)** 알고리즘을 활용해 원 검출
- 수식 6.6 원의 방정식  
  $`\left( x - a \right)^{2} + \left( y - b \right)^{2} = r^{2}`$  
  $`a = x_{center}, \quad b = y_{center}`$
- 3차원 누산 평면으로 검출
  - 각 차원은 원의 중심점 $`x`$, 원의 중심점 $`y`$, 원의 반경 $`r`$을 활용해 누산 평면을 구성함
  - 누산 평면은 2차원 공간$`\left( x, y \right)`$에서 3차원 공간 $`\left( a, b, r \right)`$으로 변환됨
- 작동 방식
  - 이미지에서 가장자리 검출
  - 3차원 히스토그램에서 도수가 높은 $`\left( a, b, r \right)`$을 선택함
    - 이미지에서 가장 긴 변의 길이가 $`N`$이라면 $`N^{3}`$ 바이트의 메모리를 필요로 함
    - 필요한 메모리가 너무 많아 비효율적
  - 2차원 방식 사용 :arrow_right: 2단계로 나눠 계산
  - 순서
      1. 가장자리에 그레이디언트 방법을 이욯애 원의 중심점 $`(a, b)`$에 대한 2차원 히스토그램 선정
          - 그레이디언트 방법: 소벨 필터를 통해 $x$, $y$에 대한 1차 소벨 도함수를 계산해 그레이디언트를 구함
      2. 모든 점에 대해 최소 거리에서 최대 거리까지 기울기의 선분을 따라 누산 평면의 모든 점을 증가시킴
          - 중심점을 선택하기 위해 중심점 후보군에서 임계값보다 크고 인접한 점보다 큰 점을 중심점으로 사용
      3. 선정된 중심점 $`\left( a, b \right)`$와 가장자리의 좌표를 원의 방정식에 대입해 반지름 $`r`$의 1차원 히스토그램으로 판단
          - 이미지에서 가장 긴 변의 길이가 $`N`$이라면 $`N^{2} + N`$ 바이트의 메모리를 필요로 함
- OpenCV 원 검출 함수는 **2단계 허프 변환(Two Stage Hough Transform)** 방법을 활용해 원 검출
  - 3차원 누산 공간을 2차원 누산 평면으로 변환해...
    - 많은 노이즈가 발생
    - 모든 중심점 후보에 대해 0이 아닌 픽셀을 모두 확인해야 함
  - 임계값을 너무 낮게 설정하면 연산 시간이 기하급수적으로 증가
  - 검출된 원이 같은 중심을 가지며 반지름이 다른 두 개 이상의 원을 가질 때 더 큰 원만 검출하기도 함
    - 입력 이미지에 노이즈가 없거나 적은 경우 발생하지 않음
- 허프 원 변환 함수
  - C#

    ```csharp
    CircleSegment[] circles = Cv2.HoughCircles(
        Mat image,
        HoughModes method,
        double dp,
        double minDist,
        double param1 = 100,
        double param2 = 100,
        int minRadius = 0,
        int maxRadius = 0
    );
    ```

  - Python

    ```python
    circles = cv2.HoughCircles(
        image,
        method,
        dp,
        minDist,
        param1=None,
        param2=None,
        minRadius=None,
        maxRadius=None
    )
    ```

  - **입력 이미지(`image`)** 를 8비트 단일 채널로 사용함
  - 각 픽셀에 그레이디언트 방향을 측정하기 위해 내부적으로 소벨 연산 수행
    - 허프 원 변환 함수는 이진화 이미지를 사용하지 않고 그레이스케일 형태의 이미지를 입력값으로 사용
  - **검출 방법(`method`)**: 항상 2단계 허프 변환 방법(21HT, 그레이디언트)만 사용
  - **해상도 비율(`dp`)**: 원의 중심을 검출하는 데 사용되는 누산 평면의 해상도
    - 1: 입력한 이미지와 동일한 해상도. 즉, 입력 이미지 너비와 높이가 동일한 누산 평면 생성
    - 2: 누산 평면의 해상도가 절반으로 줄어 입력 이미지의 크기와 반비례
  - **최소 거리(`minDist`)**
    - 일차적으로 검출된 원과 원 사이의 최소 거리
    - 원이 여러 개 검출되는 것을 줄이는 역할
  - **캐니 에지 임계값(`param1`)**
    - 허프 변환에서 자체적으로 캐니 에지를 적용하는데, 이때 사용되는 상위 임계값
    - 하위 임계값은 자동으로 상위 임계값 절반에 해당하는 값으로 할당됨
  - **중심 임계값(`param2`)**
    - 그레이디언트 방법에 적용된 중심 히스토그램(누산 평면)에 대한 임계값
    - 이 값이 낮을 경우 더 많은 원이 검출됨
  - **최소 반지름(`minRadius`)**, **최대 반지름(`maxRadius`)**
    - 검출될 원의 반지름 범위
    - 0: 검출할 수 있는 반지름에 제한 조건을 두지 않음
    - 최소 반지름과 최대 반지름에 각각 0을 입력할 경우 반지름을 고려하지 않고 검출
    - 최대 반지름에 음수를 입력할 경우 검출된 원의 중심만 반환

(예제 6.9)

(예제 6.10)

- 전처리 과정을 진행하지 않거나 부정확한 경우, 매개 변수의 값을 세밀하게 조정해야 함
- 대부분의 환경에 적용하기 위해 침식, 흐림 처리, 팽창 등의 전처리 작업을 할 수 있는 함수 활용
- 또는 허프 원 변환 매개 변수에 적절한 값을 지정하게 하는 알고리즘을 구성하거나 함수가 사용되는 주변 환경을 고려해 매개 변수 선택
- 전처리 과정이 미흡하거나 매개 변수의 값이 적절하지 않을 경우 실행 시간이 오래 걸림

### 4. QR 코드 검출

- QR 코드: Quick Response Code
- OpenCV에서는 QR 코드를 검출하고 해석하는 기능을 제공함
  - 입력 이미지에서 QR 코드를 감지하고 디코드하는 기능 제공
- QR 코드 검출기 클래스
  - C#

    ```csharp
    QRCodeDetector detector = new QRCodeDetector();
    ```

  - Python

    ```python
    detector = cv2.QRCodeDetector()
    ```

- QR 코드 검출기 단일 검출 메서드
  - C#

    ```csharp
    bool retval = detector.Detect(
        Mat img,
        out Point2f[] points
    );
    ```

  - Python

    ```python
    retval, points = detector.detect(img)
    ```

- QR 코드 검출기 단일 디코드 메서드
  - C#

    ```csharp
    string decodedInfo = detector.Decode(
        Mat img,
        IEnumerable<Point2f> points,
        Mat? straightQrCode = null
    );
    ```

  - Python

    ```python
    decodedInfo, straightQrCode = detector.decode(img, points)
    ```

- QR 코드 검출기 클래스
  - OpenCV 라이브러리에서 제공되는 QR 코드 검출기
  - 이미지나 비디오 프레임에서 QR 코드를 감지하고 디코드할 수 있는 기능 제공
- 단일 검출 메서드
  - **입력 이미지(`img`)** 에서 하나의 QR 코드를 검출해 **성공 여부(`retval`)** 와 **QR 코드 좌표(`points`)** 반환
  - QR 코드 좌표는 좌측 상단, 우측 상단, 우측 하단, 좌측 하단의 순서로 정렬됨
  - QR 코드 검출에 실패했다면 C#에서는 빈 배열, Python에서는 `None` 값 반환
- 단일 디코드 메서드
  - **입력 이미지(`img`)** 와 **QR 코드 좌표(`points`)** 를 입력해 **QR 코드 정보(`decodedInfo`)** 와 **이진화된 QR 코드 이미지(`straightQrCode`)** 반환
  - QR 코드 정보: QR 코드에서 추출한 문자열 정보가 저장됨
  - 이진화된 QR 코드 이미지: 입력 이미지에서 검출한 QR 코드 이진 정보가 담겨 있음
- 단일 검출/디코드 메서드는 이미지 안에 여러 개의 QR 코드가 존재하더라도 하나의 QR 코드만 검출 가능

- QR 코드 검출기 다중 검출 메서드
  - C#

    ```csharp
    bool retval = detector.DetectMulti(
        Mat img,
        out Point2f[] points
    );
    ```

  - Python

    ```python
    retval, points = detector.detectMulti(img)
    ```

- QR 코드 검출기 다중 디코드 메서드
  - C#

    ```csharp
    string retval = detector.DecodeMulti(
        Mat img,
        IEnumerable<Point2f> points,
        out string?[] decodedInfo,
        out Mat[] straightQrCode
    );
    ```

  - Python

    ```python
    retval, decodedInfo, straightQrCode = detector.decodeMulti(img, points)
    ```

- 다중 검출 메서드
  - 단일 검출 메서드와 동일한 형태
  - 여러 개의 QR 코드 좌표가 반환되므로 C#에서는 배열의 길이가 길어지며, Python에서는 차원이 증가함
- 다중 디코드 메서드
  - **성공 여부(`retval`)** 와 함께 **QR 코드 정보(`decodedInfo`)** 반환
  - QR 코드 정보는 1개 이상 존재하므로 배열의 형태를 지님

- QR 코드 검출기 단일 검출/디코드 통합 메서드
  - C#

    ```csharp
    string decodedInfo = detector.DetectAndDecode(
        Mat img,
        out Point2f[] points,
        Mat? straightQrCode = null
    );
    ```

  - Python

    ```python
    decodedInfo, points, straightQrCode = detector.detectAndDecode(img)
    ```

- QR 코드 검출기 다중 검출/디코드 통합 메서드: C#은 제공하지 않음
  - Python

    ```python
    retval, decodedInfo, points, straightQrCode = detector.detectAndDecodeMulti(img)
    ```

(예제 6.11)

(예제 6.12)

## 03 특징 매칭

- Feature Matching
- 두 개 이상의 이미지 간에서 특정한 부분이나 패턴을 찾고 이를 서로 연결하는 과정
- 주로 이미지 내에서 독특하게 식별 가능한 특징점이나 지역적인 특징들을 찾아 이를 활용해 이미지 간의 상응하는 부분 연결
- 비디오에서 물체나 인물의 움직임을 추적하거나 동작을 인식하는 데에도 활용 가능
- 연속된 이미지 프레임 간의 특징 매칭을 통해 물체의 경로를 추정하거나 동작 감지 가능

### 1. 배경 차분

- Background Subtraction
- 동적인 환경에서 움직이는 객체를 식별하기 위해 사용됨
- 영상에서 현재 프레임과 이전 프레임 간의 차이를 계산해 움직이는 객체나 지점 감지
- 핵심 원리: 배경에서의 변화를 감지하고 해당 영역을 추출하는 것
- 움직이는 객체의 식별을 통해 불필요한 정보를 제거하고 중요한 움직임에만 초점을 맞출 수 있음
- 종류
  - **픽셀 차분(Pixel Subtraction)**
    - 이미지의 각 픽셀 간 차이를 계산해 변화 감지
    - 현재 프레임과 이전 프레임의 픽셀 차이 계산
    - 정적인 배경에서 물체의 움직임을 감지하는 데 효과적
    - 절대값 차이 함수를 활용해 프레임 간의 각 픽셀 차이를 간단하면서도 효과적으로 계산 가능
  - **적응형 차분(Adaptive Subtraction)**
    - 주변 환경의 조건을 고려해 차분 수행
    - 주변 환경의 조건에 따라 움직임을 감지하는 것이 목표
    - 주변의 픽셀 값이 일정 범위를 벗어나면 움직임으로 간주
    - 동적인 환경에서 변화에 민감하게 대응할 수 있어 유용하게 사용됨
    - 정적인 배경이 아닌 다양한 환경에서 높인 신뢰성 제공
    - **K-최근접 이웃(K-Nearest Neighbors: KNN)**
      - 주어진 데이터 포인트와 가장 가까운 이웃들을 기반으로 예측을 수행하는 머신러닝 알고리즘
      - 동적인 환경에서도 비교적 잘 작동
      - 새로운 물체가 나타날 때 배경 모델이 유연하게 적응할 수 있음
      - K-최근접 이웃 배경 차분 클래스
        - C#

          ```csharp
          BackgroundSubtractorKNN subtractor = BackgroundSubtractorKNN.Create(
              int history = 500,
              double dist2Threshold = 400.0,
              bool detectShadows = true
          );
          ```

        - Python

          ```python
          subtractor = cv2.createBackgroundSubtractorKNN(
              history=500,
              dist2Threshold=400.0,
              detectShadows=True
          )
          ```

        - 지도 학습에서 사용되는 분류 알고리즘 방법을 활용해 배경 차분
        - **이력(`history`)**
          - 배경 모델을 학습하는 데 사용되는 프레임 수
          - 과거의 몇 프레임까지의 정보를 사용해 배경을 제거할지 결정
          - 높은 값: 모델을 더 오래 학습시키나 동적인 환경에서 더 빠르게 변화에 적응 가능
        - **거리 임계값(`dist2Threshold`)**
          - K-최근접 이웃 알고리즘에서 사용되는 임계값
          - 현재 픽셀과 가장 가까운 K 이웃들 간의 제곱 거리가 이 임계값보다 작으면 해당 픽셀을 배경으로 간주
        - **그림자 감지(`detectShadows`)**
          - 그림자 감지 여부 설정
          - `True`: 그림자 검출, 그림자 표시
          - 그림자 감지를 수행하는 경우 연산이 조금 느려짐
    - **가우시안 혼합(Mixture of Gaussians: MOG)**
      - 배경 모델을 여러 개의 가우시안 분포의 혼합으로 모델링
      - 동적인 환경에서 발생하는 여러 조건에 대응할 수 있도록 설계됨
      - 복잡한 환경에서도 배경을 효과적으로 모델링하고 움직이는 물체를 우수하게 감지 가능
      - 각각의 픽셀에 대해 여러 개의 가우시안 분포를 갱신하고 평가해야 하므로 계산 비용이 높음
      - 정적인 배경에서는 다른 기법보다 성능이 떨어질 수 있음
      - 가우시안 혼합 배경 차분 클래스
        - C#

          ```csharp
          BackgroundSubtractorMOG2 subtractor = BackgroundSubtractorMOG2.Create(
              int history = 500,
              double varThreshold = 16,
              bool detectShadows = true
          );
          ```

        - Python

        ```python
        subtractor = cv2.createBackgroundSubtractorMOG2(
            history=500,
            varThreshold=16,
            detectShadows=True
        )
        ```

        - **이력(`history`)** 과 **그림자 감지(`detectShadows`)** 매개 변수: KNN 클래스와 동일한 의미
        - **분산 임계값(`varThreshold`)**
          - 배경 모델에서 사용되는 가우시안 혼합 모델의 각 구성 요소에 대한 분산 임계값
          - 구성요소: 가우시안 혼합 모델에서 각각의 가우시안 함수
          - 각 함수는 주어진 픽셀이 배경에 속할 확률을 모델링
          - 새로운 픽셀의 분산이 해당 구성 요소의 분산 임계값보다 작으면 해당 픽셀은 배경으로 간주됨
          - 분산 임계값을...
            - 낮은 값으로 설정: 모델이 픽셀을 더 빨리 배경으로 간주
            - 높은 값으로 설정: 더 느리게 배경 갱신

(예제 6.13)

(예제 6.14)

### 2. 템플릿 매칭

- Template Matching
- 간단하고 빠른 이미지 검출 방법
- 주로 작은 규모의 이미지나 단일 객체를 찾는 데에 적합
- 주어진 입력 이미지에서 특정 템플릿 이미지와 일치하는 부분을 찾기 위한 알고리즘
  - 템플릿 이미지를 입력 이미지상에서 이동시켜 가며 두 이미지 간의 유사도를 평가는 원리를 기반으로 함
  - 주로 픽셀 간의 차이나 상관관계를 계산해 두 이미지 간의 유사성을 측정함
  - 일반적으로 유사도가 높을수록 매칭이 강하다고 판단함
- **슬라이딩 윈도우(Sliding Window)** 방식을 사용해 구현함
- 수식 6.7 템플릿 매칭 결과 크기  
  $`\left( W_{R}, H_{R} \right) = \left( W - w + 1, H - h + 1 \right)`$
  - $`W`$, $`H`$: 입력 이미지의 크기
  - $`w`$, $`h`$: 템플릿 이미지의 크기
- 두 이미지 간의 일치 여부를 직접적으로 계산하므로 추가적인 학습 데이터나 훈련이 필요하지 않아 쉽게 적용 가능
- 통계적인 방법이 아니므로 템플릿의 크기나 회전 변형에 민감하게 반응함
  - 이를 극복하기 위해...
    - 크기나 각도가 다른 여러 템플릿을 사용해 이미지 검색 후 각 템플릿에 대한 매칭 결과 중 가장 좋은 결과 선택
    - 다양한 크기와 회전에 대응할 수 있게 됨
    - **스케일 불변성(Scale Invariance)** 과 **회전 불변성(Rotation Invariance)** 을 개선해 더욱 강력한 템플릿 매칭 구현
- 템플릿 매칭 함수
  - C#

    ```csharp
    Cv2.MatchTemplate(
        Mat image,
        Mat templ,
        Mat result,
        TemplateMatchModes method,
        Mat? mask = null
    );
    ```

  - Python

    ```python
    result = cv2.matchTemplate(
        image,
        templ,
        method=None,
        result=None,
        mask=None
    )
    ```

  - **입력 이미지(`image`)** 상에서 **템플릿 이미지(`templ`)** 와 가장 유사한 패턴을 찾아 **비교 결과 맵(`result`)** 으로 반환
  - 비교 결과 맵(`result`)
    - 32비트 단일 채널 데이터
    - **템플릿 매칭 방법(`method`)** 을 통해 유사도 계산 방식 설정
  - 마스크(`mask`)
    - 특정 영역을 선택적으로 무시하기 위해 사용
    - 0이 아닌 요소에 대해서만 매칭 수행
    - 템플릿 매칭을 여러 번 수행할 때 주로 사용

  (표 6.3)

  - 템플릿 매칭 방법 플래그의 수식에서
    - $`R(x, y)`$는 비교 결과 맵
    - $`T(x, y)`$는 템플릿 이미지
    - $`I(x, y)`$는 입력 이미지
  - 템플릿 매칭 방법 플래그의 특징
    - `SqDiff` / `TM_SQDIFF`
      - 제곱차(픽셀 값 차이의 제곱) 방식으로 유사도 계산
      - 가장 작은 값이 최적의 매칭으로 간주됨
    - `SqDiffNormed` / `TM_SQDIFF_METHOD`
      - 정규화된 제곱차 방식으로 유사도 계산
      - 0에 가까운 값이 최적의 매칭으로 간주됨
    - `CCorr` / `TM_CCORR`
      - 상관 관계(Cross Correlation)로 유사도 계산
      - 값이 클수록 최적의 매칭으로 간주
    - `CCorrNormed` / `TM_CCORR_NORMED`
      - 정규화된 상관 관계로 유사도 계산
      - 값이 클수록 최적의 매칭
      - 매칭 값은 0.0 - 1.0으로 정규화됨
    - `CCoeff` / `TM_CCOEFF`
      - 상관 계수(Correlation Coefficient)로 유사도 계산
      - 1에 가까운 값이 최적의 매칭으로 간주
    - `CCoeffNormed` / `TM_CCOEFF_NORMED`
      - 정규화된 상관 계수로 유사도 계산
      - 값이 클수록 최적의 매칭
      - 매칭 값은 -1.0 - 1.0을 정규화됨
  - 제곱차 방식
    - 연산량이 적고 작은 템플릿을 찾을 때 주로 사용
    - 가장 기본적인 방식
  - 상관 관계와 상관 계수
    - 연산량이 많음
    - 일반적으로 다양한 상황에서 잘 작동
- 템플릿 매칭을 수행할 때에는 특별한 경우가 아니라면 정규화된 방식 사용
  - 정규화된 방식을 사용하지 않으면...
    - 매우 높은 값이 반환되어 불필요한 메모리가 할당될 수 있음
    - 매칭 결과를 해석하기 어려울 수 있음

(예제 6.15)

(예제 6.16)

### 3. 광학 흐름

- Optical FLow
- 영상에서 시간에 따른 객체의 움직임이나 카메라의 움직임과 같은 픽셀의 이동을 추적하는 기술
- 각 픽셀이 시간에 따라 어떻게 변하는지를 분석해 객체의 움직임을 추정함
- 특징점의 움직임, 누적 경로, 예상 경로, 속도, 속력 등 확인 가능
- 시각적으로 인식되는 움직임의 흐름을 정량화하고 해석하여 환경 변화에 대한 정보 제공
- **밀집 광학(Dense Optical Flow)**
  - 영상 내 모든 픽셀에 대해 움직임을 추적하는 기술
  - 각 픽셀마다 이동을 분석해 해당 지점의 속도 및 방향을 게산하고 전체 이미지의 움직임을 파악할 수 있음
  - 영상 내 모든 지점의 움직임 정보를 얻을 수 있어 객체나 장면의 세부적인 움직임 파악 가능
  - 정교한 추적 작업에서 주로 사용
  - 연산량이 크고 데이터의 양이 많아 처리하는 데 많은 메모리를 필요로 함
  - 각 픽셀 간의 강도 변화를 기반으로 움직임을 계산하므로 노이즈가 많거나 텍스처가 부족한 영역이라면 정확성이 떨어질 수 있음
- **희소 광학 흐름(Sparse Optical Flow)**
  - 영상 내에서 특정 지점이나 특징점의 움직임만을 추적하는 기술
  - 이미지 내에서 사전에 선택한 제한된 수의 특정 지점만으로 광학 흐름을 계산함
  - 움직임 추적 시 일부 특정 지점만을 사용하기 때문에 연산량이 줄어들어 처리 속도가 빠름
  - 추적 대상이 되는 특징의 수가 적기 때문에 화면 내에서 특징적인 지점의 움직임 정확히 파악 가능
  - 주로 실시간 처리와 같이 게산이 빠르게 이뤄져야 하는 상황에 주로 활용
  - 특징을 정확히 선택하지 않으면 정확도가 떨어질 수 있음
  - 특징 지점 간의 움직임이 크거나 빠르면 추적이 어려워짐
  - 일부 특징만 사용하기 때문에 노이즈나 이상치가 있을 경우 큰 영향을 받음

#### 파네백 알고리즘

- Farneback's Algorithm
- 밀집 광학 흐름 알고리즘의 일종
- 해석학적 기법을 기반으로 다항식 확장을 통해 광학 흐름 계산
- 입력 이미지를 다양한 해상도로 다운샘플링해 이미지 피라미드 생성, 고주파 및 저주파 성분 분석
- 각 이미지 피라미드 계층에서는 광학 흐름이 초기화되며, 다운샘플링된 이미지 간의 대략적인 이동이 추정됨
  - 이때 다항식 확장 방법을 활용해 픽셀 이동 추정
- 이미지를 이차 다항식과 각 포인트를 연관시켜 광학 흐름을 정확히 계산
- 각 해상도에서 광학 흐름이 초기화되고 픽셀 이동이 다항식을 모델링된 후  
  :arrow_right: 계산된 광학 흐름은 상위 해상도로 업샘플링되어 다음 높은 해상도의 이미지 피라미드 계층에서 활용됨
- 상위 해상도에서 광학 흐름이 갱신되면 해당 해상도에서의 광학 흐름을 다항식 확장 방법을 사용해 다시 계산
- 이 반복 과정을 통해 이미지의 각 영역에서 광학 흐름이 점진적으로 개선됨
- 각 해상도에서 계산된 광학 흐름을 최종적으로 결합하면 고해상도 이미지에서 정확하고 세밀한 광학 흐름이 얻어짐
- 다항식 확장 알고리즘은 이미지를 이차 다항식으로 각 지점을 연관시켜 변환
- 윈도 중심에 가까운 지점에 민감하게 반응할 수 있도록 가중치를 적용해 픽셀 주변의 윈도를 기반으로 근사화함
- 파네백 광학 흐름 함수
  - C#

    ```csharp
    Cv2.CalcOpticalFlowFarneback(
        Mat prev,
        Mat next,
        Mat flow,
        double pyrScale,
        int levels,
        int winSize,
        int iterations,
        int polyN,
        double polySigma,
        OpticalFlowFlags flags
    );
    ```

  - Python

    ```python
    flow = cv2.calcOpticalFlowFarneback(
        prev,
        next,
        flow=None,
        pyr_scale,
        levels,
        winsize,
        iterations,
        poly_n,
        poly_sigma,
        flags
    )
    ```

  - 8비트 단일 채널 이미지인 **이전 프레임(`prev`)** 과 **다음 프레임(`next`)** 을 사용해 두 프레임 간의 광학 흐름 계산
  - **흐름 벡터(`flow`)**
    - 부동 소수점 형식
    - 두 개의 채널이 반환됨
    - 반환 값에서 흐름 벡터를 할당해도 매개 변수에 `flow = None` 형태로 포함해야 함
  - **피라미드 스케일(`pyr_scale`)** 과 **피라미드 레벨(`levels`)** 은 이미지 피라미드를 구성하기 위한 매개 변수
    - 피라미드 스케일
      - 피라미드를 만들기 위한 이미지 크기 설정
      - 1보다 작은 값을 가져야 함
      - 0.5: 일반적인 피라미드의 크기
    - 피라미드 레벨
      - 피라미드의 계층 수 결정
      - 1: 원본 이미지만 사용
  - **윈도 크기(`winsize`)**
    - **피팅(`Fitting`)** 전에 수행되는 흐림 처리를 설정하는 커널의 크기 설정
    - 값이 클수록 노이즈의 영향이 줄고 처리 속도가 빨라지나 검출 결과가 흐릿해짐
    - 흐림 처리는 플래그를 설정해 제어 가능
  - **반복 횟수(`iterations`)**
    - 피라미드 각 계층에서 알고리즘이 수행되는 횟수
    - 클수록 결과는 정확해지지만 속도가 느려짐
  - **이차 다항식의 차수(`poly_n`)**
    - 각 픽셀에서 다항식 확장을 찾는 데 사용되는 인접 픽셀 영역 크기
    - 값이 클수록 고주파수 변동이 다항식 피팅을 주지 않아 매끄러워지며 흐린 모션 필드가 발생
    - 5 - 7 값을 가장 많이 사용
  - **가우시안 표준 편차(`poly_sigma`)**
    - 다항식 확장을 위한 가우시안 표준 편차
    - 가우시안 표준 편차는 이차 다항식 차수의 약 0.2배로 주로 사용
  - **플래그(`flags`)**
    - 두 가지 인수를 활용해 적용
    - **초기 추정치 플래그(`OpticalFlowFlags.UseInitialFlow` / `cv2.OPTFLOW_USE_INITIAL_FLOW`)**
      - 흐름 벡터를 입력값으로 취급해 초기 추정값으로 사용
      - 이전 프레임이 다음 프레임과 비슷한 움직임을 할 가능성이 있다는 가정하에 사용
    - **최소 고유값 플래그(`OpticalFlowFlags.FarnebackGaussian` / `cv2.OPTFLOW_FARNEBACK_GAUSSIAN`)**
      - 흐림 효과 단계에서 가우시안 커널 사용
      - 계산 시간이 늘어나지만 우수한 결과를 얻을 수 있음
- 수식 6.8 흐름 벡터  
  $`\text{prev}\left( x, y \right) \sim \text{next}\left( x + \text{flow}\left( x, y \right) [0], y + \text{flow}\left( x, y \right)[1] \right)`$

- 흐름 벡터 수식: 이전 프레임의 좌표를 다음 프레임의 좌표와 연결하는 근사적인 관계
- $`\text{flow}\left( x, y \right)`$: 현재 좌표에서의 흐름 벡터
- $`[0]`$, $`[1]`$: 흐름 벡터의 $`x`$ 및 $`y`$ 성분

#### 루카스-카나데 방법

- Lucas-Kanade Method
- 희소 광학 흐름 알고리즘의 일종
- 두 프레임 간의 픽셀 간 차이를 사용해 물체의 움직임 추적
- 주어진 두 프레임에서 픽셀 간의 차이를 계산하고, 이를 이용해 픽셀 속도 추정 가능
- 두 프레임 간의 물체의 상대적인 움직임 계산 가능
- 주로 연속된 영상 프레임 간의 작은 움직임을 추적하는 데 적합
- 정적인 배경에서 동적인 물체의 움직임을 추적하는 데 특히 효과적으로 사용됨
- 이 알고리즘은 다음과 같은 세 가지 가정에 의해 광학 흐름을 판단함
    1. 밝기 불변성(Brightness Constancy)
        - 프레임 내의 객체는 프레임들 사이에서 움직임이 발생하기 때문에 객체를 구성하는 픽셀은 불변
        - 그레이스케일 이미지에서 트래킹을 시도할 때 픽셀의 밝기는 변하지 않음
    2. 작은 움직임(Small Motion)
        - 프레임 간의 객체 움직임은 거의 없어 상대적으로 객체는 움직임이 적다고 가정
        - 픽셀이나 작은 이웃 픽셀 주변의 물체의 움직임(Motion Field) 선형화 가능
    3. 공간적 일관성(Spatial Coherence)
        - 인접한 픽셀의 흐름 벡터가 유사하다고 가정
        - 프레임 내에서 인접한 픽셀들을 같은 객체로 볼 수 있으며 해당 픽셀들은 동일한 움직임을 보임
        - 픽셀의 흐름 매개 변수 추정 가능
- 밝기 불변성 가정에 의해 시간 경과에 따라 객체를 구성하는 픽셀은 거의 변하지 않음
  - 시간이 지나도 장면 사이의 픽셀들은 일정함
- 수식 6.9 밝기 불변성  
  $`I \left(x, y, t \right) = I \left( x + dx, y + dy, t + dt \right)`$
- 시간적 지속성 가정에 의해 프레임 내의 움직임은 매우 작음
  - 그러므로 위의 수식 중 우항을 테일러 급수로 전개하면 다음과 같은 수식을 얻을 수 있음
- 수식 6.10 테일러 급수 전개  
  $`I \left( x + dx, y + dy, t + dt \right) \approx I \left(x, y, t \right) + \dfrac{\partial I}{\partial x}dx + \dfrac{\partial I}{\partial y}dy + \dfrac{\partial I}{\partial t}dt`$
- 테일러 급수를 이용해 우항을 전개하는 것은 작은 변위에 대한 근사를 나타냄
  - 작은 움직임이 있다는 가정에서 비롯된 것
  - 작은 변위에서만 효과적인 근사를 수행함
- 밝기 불변성이 성립하려면 테일러 급수 전개의 미분식은 합이 0이 되어야 함
  - 연쇄 법칙(Chain Rule)을 적용하고 정리하면 다음과 같은 수식이 됨
- 수식 6.11 연쇄 법칙 적용  
  $`\dfrac{\partial I}{\partial x}\dfrac{dx}{dt} + \dfrac{\partial I}{\partial y}\dfrac{dy}{dt} + \dfrac{\partial I}{\partial t}\dfrac{dt}{dt} = 0`$  
  $`I_{x}V_{x} + I_{y}V_{y} + I_{t} = 0`$
- 각 이미지에 대한 $`n`$ 방향 편미분을 $`I_{n}`$의 형태로 표기하고 $`dx/dt`$와 $`dy/dt`$는 속도로 정리함
  - 이 수식을 단일 벡터 방정식으로 변환하면 다음과 같이 변환됨
- 수식 6.12 단일 벡터 방정삭  
  $`\nabla I^{T}\cdot \overrightarrow{V} = -I_{t}`$
- 이 수식은 하나의 방정식에 미지수가 두 개($`V_{x}`$, $`V_{y}`$)가 발생함
  - 그러므로 방정식을 풀 수 없어 2차원 모션 벡터에 대한 해를 구할 수 없음
  - 이는 작은 윈도에서 조리개 문제로 인해 발생함
    - 작은 조리개를 통해 움직임을 감지할 때 윤곽으로는 객체가 어떤 방향으로 움직이는지 정확히 결정하기 어려움
  - 이때 공간적 일관성 가정에 의해 수식을 품
- 수식 6.13 공간적 일관성 가정 적용  
  $`\begin{bmatrix} I_{x}\left( p_{1} \right) & I_{y}\left( p_{1} \right) \\ I_{x}\left( p_{2} \right) & I_{y}\left( p_{2} \right) \\ \vdots & \vdots \\ I_{x}\left( p_{n} \right) & I_{y}\left( p_{n} \right) \end{bmatrix} \begin{bmatrix} V_{x} \\ V_{y} \end{bmatrix} = - \begin{bmatrix} I_{t}\left( p_{1} \right) \\ I_{t}\left( p_{2} \right) \\ \vdots \\ I_{t}\left( p_{n} \right) \end{bmatrix}`$
- $`m \times n`$ 윈도 크기에 대해 픽셀들이 동일한 움직임을 보인다고 가정하면 방정식을 쉽게 풀 수 있음
  - 위의 행렬식으로 작성되며 $`Av = -b`$의 형태가 구성됨
  - $`Av = -b`$를 풀게 되면 미지수의 개수보다 더 많은 방정식이 생성되어 과도하게 제약된 시스템을 구성하게 됨
  - 이 문제를 해결하기 위해 최소 제곱법으로 미지수를 구함
- 수식 6.14 최소 제곱법 적용  
  $`A^{T}Av = -A^{T}b`$  
  $`\begin{bmatrix} \sum I_{x}I_{x} & \sum I_{x}I_{y} \\ \sum I_{y}I_{x} & \sum I_{y}I_{y} \end{bmatrix} \begin{bmatrix} V_{x} \\ V_{y} \end{bmatrix} = - \begin{bmatrix} \sum I_{x}I_{t} \\ \sum I_{y}I_{t} \end{bmatrix}`$
- 위 수식을 다시 속도(흐름)에 대해 정리하면 다음과 같음
- 수식 6.15 광학 흐름 추정  
  $`\begin{bmatrix} V_{x} \\ V_{y} \end{bmatrix} = \left( A^{T}A \right)^{-1} - A^{T}b`$
- 루카스-카나데 알고리즘은 윈도에 대한 정보로 움직임을 검출하므로 희소 상황에서도 높은 검출률을 보일 수 있음
- 윈도는 프레임에 비해 작은 크기를 가지므로 큰 움직임이 발생할 경우 윈도 외부로 픽셀이 움직일 수 있어 검색이 불가능할 수도 있음
  - 윈도 크기를 너무 크게 잡을 경우 공간적 일관성이 어긋남
  - 윈도 크기를 너무 작게 잡을 경우 조리개 문제가 발생함
- 위의 문제를 최소화하기 위해 이미지 피라미드 활용
  - 가장 상단의 피라미드에서 광학 흐름을 계산하고 다음 피라미드에서 추정 결과 사용
  - 이 연산을 가장 하단의 피라미드에 도달할 때까지 반복해 초기 가정을 개선하게 됨
  - 가정 위반이 최소화되어 더 효과적인 움직임 추적 가능
- 루카스-카나데 광학 흐름 함수
  - C#

    ```csharp
    Cv2.CalcOpticalFlowPyrLK(
        Mat prevImg,
        Mat nextImg,
        Mat prevPts,
        Mat nextPts,
        Mat status,
        Mat err,
        Size? winSize = null,
        int maxLevel = 3,
        TermCriteria? criteria = null,
        OpticalFlowFlags flags = OpticalFlowFlags.None,
        double minEigThreshold = 1e-4
    );
    ```

  - Python

    ```python
    nextPts, status, err = cv2.calcOpticalFlowPyrLK(
        prevImg,
        nextImg,
        prevPts,
        nextPts,
        status=None,
        err=None,
        winSize=(21, 21),
        maxLevel=3,
        criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 30, 0.01),
        flags=0,
        minEigThreshold=1e-4
    )
    ```

  - 8비트 단일 채널 이미지 또는 다중 채널 이미지인 **이전 프레임(`prevImg`)** 과 **다음 프레임(`nextImg`)** 을 사용해 두 프레임 간의 광학 흐름을 계산함
    - 두 프레임은 같은 이미지 크기와 동일한 채널 수를 가져야 함
  - **이전 특징점(`prevPts`)**: 프레임상에서 추적하고자 하는 지점
  - **다음 특징점(`nextPts`)**
    - 이전 특징점이 이동한 위치
    - 이전 특징점과 비교해 객체의 움직임 확인 가능
  - **상태(`status`)**
    - 각 지점에 대한 추정 성공 여부
    - 1: 이전 특징점에서 다음 특징점이 발견됨
    - 0: 이전 특징점에서 다음 특징점이 발견되지 않음
  - **오차(`err`)**
    - 이전 특징점과 다음 특징점에 대한 오류 측정
    - 다음 특징점이 발견되지 않으면 오차는 미발생
  - **윈도 크기(`winSize`)**: 각 피라미드 계층에서 검색할 윈도의 크기
  - **피라미드 최대 레벨(`maxLevel`)**: 0으로 지정할 경우 이미지 피라미드는 사용되지 않음
  - **기준(`criteria`)**: 알고리즘이 종료될 시점 설정
  - **플래그(`flags`)**
    - 초기 추측값이나 고유값의 사용 여부
    - 사용하지 않거나 하나 이상 사용할 수 있음
    - 초기 추정치 플래그를 사용할 경우 객체의 초기 추측 좌표에 사용할 배열을 이전 특징점 대신 다음 특징점으로 사용
    - 최소 고유값 플래그를 사용할 경우 오차를 해리스 행렬의 최소 고유치로 반환
  - **최소 고유 임계값(`minEigThreshold`)**: 추적하기에 좋지 않은 지점을 제거하는 필터 기능

(예제 6.17)

(예제 6.18)

- 루카스-카나데 방법은 특징점을 기반으로 광학 흐름을 추적하므로 특징점이 영상의 경계를 벗어나거나 사라진다면 더 이상 추적이 불가능
- 특징점을 생성하는 알고리즘이 아니므로 특징점이 모두 사라지면 더 이상 추적이 불가능

### 4. 키 포인트 매칭

- Key Point Matching
- 두 이미지 간 유사한 부분을 찾아내어 서로 매칭시키는 프로세스
- **키 포인트(Key Point)**: 이미지에서 특별히 중요한 지점
  - 주로 이미지에서 특징적이며 서로 다른 영역을 대표하는 지점
  - 이미지의 특이한 부분을 나타내며, 일반적으로 특징적이고 서로 다른 영역을 대표하는 지점으로 간주됨
  - 이러한 키 포인트를 매칭하기 위해 기술자를 사용함
- **기술자(Descriptor)**
  - 각 키 포인트에 대한 특징적인 표현으로 해당 지점이나 객체를 설명함
  - 해당 지점의 특성을 나타내는 특성 벡터
  - 특정 위치의 특성을 추출해 해당 지점이 유일하게 식별될 수 있도록 함
  - 특정 위치에서 주변 영역의 정보를 수집하고 특징을 추출해 표현하며, 비슷한 특성을 가진 다른 지점들과의 구별을 가능하게 함
  - 완전히 다른 이미지나 빠른 프레임에서도 객체를 추적할 수 있게 됨

#### ORB 알고리즘

- Oriented FAST and rotated BRIEF
- FAST 알고리즘, BRIEF 알고리즘, 해리스 코너 알고리즘을 결합함
  - FAST: 키 포인트를 빠르게 검출하는 데 사용
  - BRIEF: 특징 주변의 **이진 기술자(Binary Descriptors)** 를 생성하는 데 활용됨
- 결합된 알고리즘은 회전에 대한 **강건성(robustness)** 을 향상시키고 빠른 속도로 키 포인트를 검출하고 기술하는 데 사용됨

##### FAST 알고리즘

- Features from Accelerated Segment Test
- 특징 검출기 알고리즘
- 이미지상의 키 포인트를 빠르게 검출하는 데 사용
- 중심 픽셀 P와 이를 둘러싼 작은 원 위에 있는 16개의 픽셀을 살펴보고 어두운 픽셀, 밝은 픽셀, 또는 주변과 유사한 픽셀로 분류
- 임계값과 연속성 조건을 활용해 키 포인트 식별
- 임계값
  - 중심 픽셀 P와 다른 픽셀들 중에서 얼마나 많은 픽셀이 어두운지 또는 밝은지를 결정하는 역할
  - 임계값을 통과하지 못한 픽셀들은 키 포인트로 식별되지 않음
  - 임계값을 조절해 키 포인트의 감도와 정확도 조절
  - 높은 임계값은 더 정확한 키 포인트를 얻을 수 있으나 더 많은 키 포인트를 놓칠 수 있음
  - 낮은 임계값은 더 많은 키 포인트를 검출하지만 노이즈에 민감해짐
- 연속성 조건
  - 중심 픽셀 P를 중심으로 선택된 16개의 픽셀 중 일정 수의 연속된 픽셀들이 어둡거나 밝은지 확인
  - 이 조건을 충족하지 못하는 경우 키 포인트로 식별되지 않음
  - 노이즈나 잘못된 감지를 방지하고 일정한 패턴으 키 포인트를 찾기 위한 조건
- 조건을 모두 만족해도 인접한 픽셀을 모두 키 포인트로 인식하는 문제가 발생할 수 있음
  - 각 키 포인트에 대한 점수를 정의하고 더 점수가 높은 키 포인트에 인접해 있는 낮은 점수의 키 포인트롤 모두 제거함
- 수식 6.16 FAST 알고리즘 점수 부여 방식  
  $`score = \max{\left( \underset{x\in \{ brighter \} }{\sum} \left| I_{x} - I_{p} - t \right|, \underset{x\in \{ darker \} }{\sum} \left| I_{x} - I_{p} - t \right| \right)}`$
  - 더 밝은 픽셀과 중앙 픽셀 사이의 절대값 차이의 합을 계산함
  - 동일하게 더 어두운 픽셀과 중앙 픽셀 사이의 절대값 차이의 합을 계산해 두 값 중 더 큰 값을 코너의 점수로 부여함
- FAST 알고리즘은 픽셀의 강도를 빠르게 비교해 특징점을 식별하므로, 계산 효율성이 뛰어남
- 16개의 픽셀만을 고려하므로 다른 방법에 비해 계산 비용이 낮음
- 주변 픽셀과의 비교를 통해 특징을 식별하기 때문에 이미지의 변화에 강하며, 회전 및 크기 변환에 대해서도 상대적으로 불변적

##### BRIEF 알고리즘

- Binary Robust Independent Elementary Features
- 칼론더 특징이라고도 함
- 이미 검출된 특징점에 대한 기술자를 생성하는 데 중점을 둠
- 특징점 주변의 지역에서 이진 기술자를 생성하는 방식으로 작동
- 이진 기술자는 특징점 주변에서 랜덤하게 선택된 특정 위치의 픽셀 쌍에 대해 이진 테스트를 수행함
  - 주어진 두 픽셀의 밝기를 비교해 이진 코드를 생성하는 방식
  - 가우시안 커널을 사용해 이미지를 부드럽게 만듦  
    :arrow_right: 특징 중심 주변의 가우스 분포를 통해 첫 번째 지점과 두 번째 지점을 계산해 모든 픽셀을 한 쌍으로 생성
  - 두 개의 픽셀을 하나의 그룹으로 묶는 방식
- BRIEF 기술자는 키 포인트 주변 영역의 단일 픽셀을 다른 단일 픽셀과 단순히 비교해 해당 지점을 설명하는 이진 코드를 생성함

##### ORB 알고리즘

- 키 포인트를 검출하기 위해 FAST 알고리즘 사용
  - 빠른 속도로 코너 검출 가능
  - 가장자리에서도 반응하는 경향
  - 이를 극복하기 위해 해리스 코너 검출 알고리즘을 도입해 최상위 특징점만을 추출
- 이미지 피라미드를 사용해 다양한 스케일에서의 검출 수행
  - 객체나 특징이 다양한 크기에서 나타날 때 높은 신뢰성을 제공하기 위해 적용
  - 스케일 공간 검색 후 특징점 주변의 박스에서 X축과 Y축을 기준으로 1차 모멘트 계산
    - 특징점 주변의 강도 분포에 대한 정보를 제공
    - 그레이디언트 방향을 통해 특징의 방향 추정 가능
  - 1차 모멘트를 사용해 방향을 추정한 후, 해당 방향을 기반으로 회전 불변성을 갖는 특징 벡터 계산
- 특징은 객체나 특징의 회전에 대해 불변성을 유지하며 방향 정보를 포함하게 됨
- ORB(Oriented FAST and rotated BRIEF) 클래스
  - C#

    ```csharp
    ORB orb = ORB.Create(
        int nFeatures = 500,
        float scaleFactor = 1.2f,
        int nLevels = 8,
        int edgeThreshold = 31,
        int firstLevel = 0,
        int wtaK = 2,
        ORBScoreType scoreType = ORBScoreType.Harris,
        int patchSize = 31,
        int fastThreshold = 20
    );
    ```

  - Python

    ```python
    orb = cv2.ORB.create(
        nfeatures=500,
        scaleFactor=1.2f,
        nlevels=8,
        edgeThreshold=31,
        firstLevel=0,
        WTA_K=2,
        scoreType=cv2.ORB_HARRIS_SCORE,
        patchSize=31,
        fastThreshold=20
    )
    ```

  - **최대 특징 수(`nfeatures`)**
    - ORB 객체가 한 번에 검출하고자 하는 특징점의 개수
    - 너무 많으면 연산 비용이 증가됨
    - 너무 적으면 이미지의 다양한 부분을 포착하지 못할 수 있음
  - **스케일 계수(`scaleFactor`)**
    - 이미지 피라미드를 설정함
    - 2: 이미지 크기가 절반이 되는 고전적인 이미지 피라미드
    - 너무 크게 지정하면 특징점의 매칭 확률이 떨어짐
    - 작게 지정하면 더 많은 피라미드 계층을 구성해야 하므로 연산 속도가 느려짐
  - **피라미드 레벨(`nlevels`)**: 이미지 피라미드의 계층 수
  - **경계 임계값(`edgeThreshold`)**: 이미지 테두리에서 발생하는 특징점을 무시하기 위한 경계의 크기
  - **시작 피라미드 레벨(`firstLevel`)**
    - 원본 이미지를 입력할 피라미드의 계층
    - 너무 높게 설정하면 피라미드 이미지의 노이즈로 인해 낮은 스케일에서 특징이 생성됨
  - **비교점(`WTA_K`)**
    - BRIEF 기술자가 구성하는 비교 비트
    - 2: 이진 형식
    - 3: 3자 간 비교 결과로 (0, 1, 2) 사용
    - 4; 4자 간 비교 결과로 (0, 1, 2, 3) 사용
    - 2(1비트), 3(2비트), 4(2비트)의 값만 지정해 비교할 수 있음
  - **점수 타입(`scoreType`)**
    - 특징의 순위를 매기는 데 사용
    - **해리스 코너(`cv2.ORB_HARRIS_SCORE`)** 방식과 **FAST(`cv2.ORB_FAST_SCORE`)** 방식 사용 가능
    - 해리스 코너 방식이 더 높은 정확도를 보이나 FAST 방식에 비해 다소 느림
  - **패치 크기(`patchSize`)**
    - 방향성을 갖는 BRIEF 기술자가 사용하는 개별 특징의 패치 크기
    - 경계 임계값 매개 변수와 상호작용하므로 패치 크기의 값을 변경한다면 경계 임계값이 패치 크기의 값보다 커야 함
  - **FAST 임계값(`fastThreshold`)**: FAST 검출기에서 사용되는 임계값
- 키 포인트 및 기술자 계산 메서드
  - C#

    ```csharp
    orb.DetectAndCompute(
        Mat image,
        Mat? mask,
        out KeyPoint[] keypoints,
        Mat descriptors,
        bool useProvidedKeypoints = false
    );
    ```

  - Python

    ```python
    keypoints, descriptors = orb.detectAndCompute(
        image,
        mask,
        descriptors=None,
        useProvidedKeypoints=False
    )
    ```

  - **입력 이미지(`image`)**: 8비트 단일 채널 이미지
  - **마스크 이미지(`mask`)**
    - 해당 마스크가 0이 아닌 위치에서만 특징점을 검출하고 계산
    - 특정 영역에 대한 특징을 찾거나 이미지의 일부를 무시하고자 할 때 사용
  - 연산 결과로 특징점에 대한 정보를 포함하는 **키 포인트(`keypoints`)** 와 각 키 포인트에 대한 **기술자(`descriptors`)** 반환
    - 기술자
      - 해당 특징점을 설명하는 데 사용
      - 후속 작업에서 특징점을 비교하는 데 활용
  - **키 포인트 사용(`useProvidedKeypoints`)** 이 참 값인 경우 키 포인트를 감지하는 대신 입력으로 사용
  - 키 포인트는 **좌표**,**지름**, **각도**, **응답**, **옥타브**, **클래스ID** 를 포함함
    - 좌표: 키 포인트의 위치
    - 지름: 키 포인트의 주변 영역
    - 각도: 키 포인트의 방향, -1일 경우 방향 없음
    - 응답: 키 포인트가 존재할 확률로 해석
    - 옥타브: 키 포인트를 추출한 피라미드의 스케일
    - 클래스ID: 키 포인트에 대한 저장 공간을 생성할 때 해당 객체를 식별하기 위해 수행한 클러스터링 결과물의 객체 ID

#### BF 매칭

- Brute Force Matching
- 가능한 모든 매칭 조합을 시도해 가장 적절한 매칭을 찾는 방법
  - 객체의 이미지와 객체가 포함된 이미지의 각 특징점을 모두 찾아 기술자를 활용
- 가장 우수한 매칭을 판단하기 위해 키 포인트 간의 거리 측정
  - 거리가 짧을수록 추수한 매칭
- 거리를 계산하는 데 사용할 거리 계산법만 요구
  - 단순하고 직관적
  - 많은 계산이 필요하므로 큰 데이터 세트나 복잡한 이미지에서는 성능 저하
- BF 매칭 클래스
  - C#

    ```csharp
    BFMatcher bf = new BFMatcher(
        NormTypes normType = NormTypes.L2,
        bool crossCheck = false
    );
    ```

  - Python

    ```python
    bf = cv2.BFMatcher(
        normType = cv2.NORM_L2,
        crossCheck=False
    )
    ```

  - 두 가지 매개 변수만 활용해 객체 인식 가능
  - **거리 측정법(`normType`)**: 질의 기술자와 훈련 기술자를 비교할 때 사용되는 거리 계산법 지정
    - 질의: 객체를 탐지할 이미지
    - 훈련: 질의 공간에서 검출할 요소
    - **질의 기술자(`Query Descriptors`)**
      - 질의 이미지에서 검출된 특징점들에 대한 기술자
      - 이미지에서 특징점을 검출한 후, 각 특징점에 대한 특징을 설명하는 기술자
    - **훈련 기술자(`Train Descriptors`)**
      - 훈련 이미지나 데이터세트에서 나온 키 포인트에 대한 기술자
      - 어떤 객체 또는 장면을 나타내는 데 사용
  - **교차 검사(`crossCheck`)**
    - 훈련된 집합에서 질의 집합이 가장 가까운 이웃이면서 동시에 질의 집합에서도 훈련된 집합이 가장 가까운 이웃이라고 판단되면 서로 매칭된 것으로 간주
    - 올바르지 않은 매칭을 제거하는 데 효율적이지만 연산 시간이 증가함

  (표 6.4)
- 매치 메서드
  - C#

    ```csharp
    DMatch[] match = bf.Match(
        Mat queryDescriptors,
        Mat trainDescriptors,
        Mat? mask = null
    );
    ```

  - Python

    ```python
    match = bf.match(
        queryDescriptors,
        trainDescriptors,
        mask
    )
    ```

  - **질의 기술자(`queryDescriptors`)** 와 **훈련 기술자(`trainDescriptors`)** 를 사용해 최적의 매칭을 찾음
  - 질의 기술자와 훈련 기술자는 각각 첫 번째 이미지와 두 번째 이미지의 키 포인트 기술자를 의미함
  - 이 메서드는 매칭된 특징점 간의 거리를 기반으로 한 매칭 결과를 반환함
  - **마스크(`mask`)**: 매칭을 할 때 특정 매칭을 무시하는 데 사용
  - 반환값 `match`
    - DMatch(Dictionary Match)를 의미함
    - 매칭 정보가 담긴 4개의 멤버를 가짐
    - `DMatch` 객체는 **질의 색인**, **훈련 색인**, **이미지 색인**, **거리** 로 구성됨
  - 질의 색인과 훈련색인: 두 이미지의 키 포인트에서 서로 매칭하기 위해 식별되는 색인 값
  - 이미지 색인: 이미지와 사전 사이에서 매칭된 경우 훈련에 사용된 이미지를 구별하는 색인 값
  - 거리: 각 키 포인트 간 유클리드 거리 또는 매칭의 품질, 거리 값이 작을수록 매칭이 정확함
- 매칭 그리기 함수
  - C#

    ```csharp
    Cv2.DrawMatches(
        Mat img1,
        IEnumerable<KeyPoint> keypoints1,
        Mat img2,
        IEnumerable<KeyPoint> keypoints2,
        IEnumerable<DMatch> matches1To2,
        Mat outImg,
        Scalar? matchColor = null,
        Scalar? singlePointColor = null,
        IEnumerable<byte>? matchesMask = null,
        DrawMatchesFlags flags = DrawMatchesFlags.Default
    );
    ```

  - Python

    ```python
    outImg = cv2.drawMatches(
        img1,
        keypoints1,
        img2,
        keypoints2,
        matches1to2,
        outImg,
        matchColor=None,
        singlePointColor=None,
        matchesMask=None,
        flags=cv2.DRAW_MATCHES_FLAGS_DEFAULT
    )
    ```

  - **질의 이미지(`img1`)** 와 **훈련 이미지(`img2`)** 를 이어 붙인 **출력 이미지(`outImg`)** 생성
  - 출력 이미지 위에 **질의 이미지 특징점(`keypoints1`)** 과 **훈련 이미지 특징점(`keypoints2`)** 을 연결한 선을 그림
  - **DMatch 객체(`matches1to2`)** 로 매칭 목록을 정의하며 이 목록에 의해 그려질 연결선의 개수가 정해짐
  - 매칭된 연결선은 **매칭 색상(`matchColor`)** 의 색상으로 그려짐
  - 매칭되지 않은 특징은 **비매칭 색상(`singlePointColor`)** 의 색상으로 그려짐
  - **매치 마스크(`matchesMask`)**: 시각화하지 않을 매칭 목록을 정의해 매치 마스크의 요소가 0이 아닌 항목만 그림
  - **플래그(`flags`)**
    - 특징점과 매칭 정보에 대한 시각화를 결정
    - OR 연산으로 결합해 사용 가능

  (표 6.5)

(예제 6.19)

(예제 6.20)
